{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary package for unsupervised learning\n",
        "! pip install unsloth"
      ],
      "metadata": {
        "id": "fqD_NG7Zm5Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Define the path for the training dataset (ensure no sensitive info in path). The dataset should contain two columns:\n",
        "# - \"mail\": This is the input text to be used for training.\n",
        "# - \"CatÃ©gorie du ticket\": This is the annotation, representing the target category for classification.\n",
        "HOME_PATH = \"/home/ubuntu/\"\n",
        "train_dataset_name = os.path.join(HOME_PATH, \"train_set_filtred.csv\")\n",
        "\n",
        "# Load the dataset from CSV file\n",
        "dataset = load_dataset(\"csv\",data_files = train_dataset_name)\n",
        "\n",
        "# Print dataset details: number of prompts and column names\n",
        "print(f'Number of prompts: {len(dataset)}')\n",
        "print(f'Column names are: {dataset.column_names}')"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "7qlQeJqCGx7d1Ycq59I13L",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "iWzbf2JM6kMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary components from unsloth for language llm\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# Load pre-trained language model with options for memory optimization (4-bit)\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"unsloth/Qwen2.5-14B-Instruct-bnb-4bit\",\n",
        "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "\n",
            "\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.1.5: Fast Qwen2 patching. Transformers: 4.49.0.dev0.\n",
            "   \\\\   /|    GPU: NVIDIA A10. Max memory: 21.975 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "\n"
          ],
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": [
            "\n",
            "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2025-01-20 15:34:44.077835: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-01-20 15:34:44.091037: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1737387284.106257   10466 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1737387284.110882   10466 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-20 15:34:44.126707: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "\n",
            "\n",
            "oading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.03s/it]"
          ],
          "output_type": "stream"
        }
      ],
      "metadata": {
        "datalore": {
          "node_id": "23IFaOGJaGijPbSwDiLNOc",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "3ZG9LkMBswg7vdNgrxr35R"
          }
        },
        "id": "agG_i4Ph6kMX",
        "outputId": "b3cd05ed-645e-4612-9067-4eb871b488fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],  # we train all language layers and MLP layers\n",
        "    use_rslora=True,\n",
        "    use_gradient_checkpointing=\"unsloth\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "Unsloth 2025.1.5 patched 48 layers with 48 QKV layers, 48 O layers and 48 MLP layers.\n"
          ],
          "output_type": "stream"
        }
      ],
      "metadata": {
        "datalore": {
          "node_id": "1gNNFNKyoRUcU1zKamHxI9",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "sqofyOVXSsqTYKwVTBMqf2"
          }
        },
        "id": "1IDHBosI6kMY",
        "outputId": "c03ec36c-a119-4d24-8c75-5088bacb0175"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt for ticket classification assistant\n",
        "prompt = \"\"\"\n",
        "Tu es un assistant spÃ©cialisÃ© dans la classification de tickets Ã  partir de leur contenu textuel. Ton objectif est dâ€™analyser la description fournie et de lâ€™associer Ã  lâ€™une des catÃ©gories ci-dessousâ€¯:\n",
        "```\n",
        "Demande de service/Backup #BCS/Autre - Autre\n",
        "Demande de service/Backup #BCS/Demande de renseignement - Demande de renseignement\n",
        "Demande de service/Backup #BCS/Restauration qualifiÃ©e - Restauration qualifiÃ©e\n",
        "Demande de service/Backup #BCS/StratÃ©gie de sauvegarde/CrÃ©ation - CrÃ©ation\n",
        "Demande de service/Backup #BCS/StratÃ©gie de sauvegarde/Modification - Modification\n",
        "Demande de service/Backup #BCS/StratÃ©gie de sauvegarde/Suppression - Suppression\n",
        "Demande de service/Cyber SÃ©curitÃ© #CS2/Bastion/CrÃ©ation-Modification d'entrÃ©es - CrÃ©ation-Modification d'entrÃ©es\n",
        "Incidents/Backup #BCS/Sauvegarde - Sauvegarde\n",
        "Incidents/Supervision - Supervision\n",
        "```\n",
        "### RÃ¨gles :\n",
        "1. RÃ©ponds uniquement par la catÃ©gorie exacte, sans texte supplÃ©mentaire.\n",
        "2. La catÃ©gorie associÃ©e doit Ãªtre unique.\n",
        "3. Si aucune catÃ©gorie ne correspond, la valeur de \"categorisation\" doit Ãªtre \"unknown\".\n",
        "\n",
        "### Exemple :\n",
        "La description:\n",
        "BonjourÂ¤ Merci de relancer les sauvegardes FULLÂ¤ si ils ne sont pas repassÃ©es en automatique. Ghislain EnvoyÃ© de mon iPhone DÃ©but du message transfÃ©rÃ©\n",
        "#### Sortie :\n",
        "{{\n",
        "  \"categorisation\": \"Incidents/Backup #BCS/Sauvegarde - Sauvegarde\"\n",
        "}}\n",
        "\n",
        "Analyse uniquement la description suivante :\n",
        "{content}\n",
        "\"\"\"\n",
        "\n",
        "# Format for predicting the category for each sample\n",
        "prediction_format = \"\"\"\n",
        "{{\n",
        "  \"categorisation\": \"{category}\"\n",
        "}}\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "8fiUoToddYq7VNMuEF8T6p",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "pBEqrMuk5fbJlQpfumfJ5g"
          }
        },
        "id": "GdBJ9Bey6kMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to convert data into a conversation format\n",
        "def convert_to_conversation(sample):\n",
        "    new_conversation = [\n",
        "        { \"role\": \"user\",\n",
        "          \"content\" : prompt.format(content = sample[\"mail\"]),\n",
        "        },\n",
        "        { \"role\": \"assistant\",\n",
        "          \"content\" : prediction_format.format(category = sample[\"CatÃ©gorie du ticket\"])\n",
        "        }\n",
        "    ]\n",
        "    return {\"messages\" : new_conversation}"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "hdAU5S6XNUlFPCwsHKwO5g",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "sCmXNGg3E01Oq1fGnfp8zn"
          }
        },
        "id": "2E947Wl06kMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to a conversation format\n",
        "converted_dataset = [convert_to_conversation(sample) for sample in dataset['train']]\n",
        "converted_dataset[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'user',\n",
              "   'content': '\\nTu es un assistant spÃ©cialisÃ© dans la classification de tickets Ã  partir de leur contenu textuel. Ton objectif est dâ€™analyser la description fournie et de lâ€™associer Ã  lâ€™une des catÃ©gories ci-dessous\\u202f:\\n```\\nDemande de service/Backup #BCS/Autre - Autre\\nDemande de service/Backup #BCS/Demande de renseignement - Demande de renseignement\\nDemande de service/Backup #BCS/Restauration qualifiÃ©e - Restauration qualifiÃ©e\\nDemande de service/Backup #BCS/StratÃ©gie de sauvegarde/CrÃ©ation - CrÃ©ation\\nDemande de service/Backup #BCS/StratÃ©gie de sauvegarde/Modification - Modification\\nDemande de service/Backup #BCS/StratÃ©gie de sauvegarde/Suppression - Suppression\\nDemande de service/Cyber SÃ©curitÃ© #CS2/Bastion/CrÃ©ation-Modification d\\'entrÃ©es - CrÃ©ation-Modification d\\'entrÃ©es\\nIncidents/Backup #BCS/Sauvegarde - Sauvegarde\\nIncidents/Supervision - Supervision\\n```\\n### RÃ¨gles :\\n1. RÃ©ponds uniquement par la catÃ©gorie exacte, sans texte supplÃ©mentaire.\\n2. La catÃ©gorie associÃ©e doit Ãªtre unique.\\n3. Si aucune catÃ©gorie ne correspond, la valeur de \"categorisation\" doit Ãªtre \"unknown\".\\n\\n### Exemple :\\nLa description:\\nBonjourÂ¤ Merci de relancer les sauvegardes FULLÂ¤ si ils ne sont pas repassÃ©es en automatique. Ghislain EnvoyÃ© de mon iPhone DÃ©but du message transfÃ©rÃ©\\n#### Sortie :\\n{\\n  \"categorisation\": \"Incidents/Backup #BCS/Sauvegarde - Sauvegarde\"\\n}\\n\\nAnalyse uniquement la description suivante :\\n[RXL] Rapport taux de succÃ¨s mensuel To: a015a4c2b329dd7d0940b642caee3ec8f73f70f1785438eda0be59c84dea2ceb BonjourÂ¤ Dans le cadre du comitÃ© de pilotage de RexelÂ¤ jâ€™ai besoin de remonter le taux de succÃ¨s des sauvegardes sur un mois. Avons-nous un report donnant cette information que vous pourriez me transfÃ©rer ? Si ouiÂ¤ pouvez-vous me le transfÃ©rer et mâ€™ajouter dans la liste de diffusion ? Si ce report mensuel nâ€™existe pasÂ¤ je pourrais me baser sur ce mail que je trouve dans la boite 066f4f74376b735364e8e978c9d64f1dfdbd1e834f843b05c0629972bda5e280 : Malheureusement je nâ€™ai que deux mails de ce type dans la boiteÂ¤ pour une raison inconnue. Je ne peux donc pas concatÃ©ner les mois de Septembre et Octobre pour en sortir le taux mensuel. Si vous avez ces mails depuis le 01/09/2024 je suis preneur ðŸ˜Š . MerciÂ¤ Cdt. Guillaume BONNAIRE Service Delivery Manager 5 rue Jacqueline Auriol 78280 Guyancourt Mobile : ++ 33 6 07 19 79 59 Support : 0 800 22 24 24 | Espace client 1b99f12e6198f4bb827c612c2f0c2dd30afc6141e3ee0db33f206790bc61aa1d Cet e-mail et toutes les piÃ¨ces jointes sont Ã©tablis Ã  lâ€™intention exclusive de ses destinataires et sont strictement confidentiels. S\\'il ne vous est pas destinÃ©Â¤ nous vous remercions de le dÃ©truire immÃ©diatementÂ¤ sans le copierÂ¤ ni rÃ©vÃ©ler ou transmettre son contenu Ã  quiconque. This e-mail and all attachments are intended for the exclusive use of the recipients and are strictly confidential. If you are not the named recipient of this messageÂ¤ please destroy it without readingÂ¤ copying or disclosing its contents to any other person. Chez ANTEMETAÂ¤ nous travaillons avec flexibilitÃ©. Je n\\'attends donc pas de rÃ©ponse ou d\\'action immÃ©diate aux e-mails envoyÃ©s en dehors de vos heures habituelles de travail. At ANTEMETAÂ¤ we work flexibly so whilst it suits me to e-mail nowÂ¤ I do not expect a response or action outside of your own working hours.\\n'},\n",
              "  {'role': 'assistant',\n",
              "   'content': '\\n{\\n  \"categorisation\": \"Demande de service/Backup #BCS/Autre - Autre\"\\n}\\n'}]}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "metadata": {
        "datalore": {
          "node_id": "mc1MEvNxOtheo2tu6TtV1B",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "mzaoFLw5IL170UzgwlvWWS"
          }
        },
        "id": "3f_sYK3q6kMZ",
        "outputId": "c55b0a6d-eaaa-484f-e128-e0894311b618"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to format prompts for tokenization\n",
        "def formatting_prompts_func(examples):\n",
        "    try:\n",
        "        convos = examples[\"dataset\"]\n",
        "        texts = [tokenizer.apply_chat_template(convo['messages'], tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "        return { \"text\" : texts, }\n",
        "    except:\n",
        "        print('error')\n",
        "        raise"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "KpFcYg7cbNXrpzwJ2jOLXj",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "UeVWy67Obm8FqvkZQsR1FG"
          }
        },
        "id": "kGvIz4Ql6kMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to a format suitable for processing\n",
        "from datasets import Dataset\n",
        "my_dataset = Dataset.from_dict({\"dataset\": converted_dataset})"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "wuha3TDXJfBzJ7xxLFmY9d",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "Uibx73yiDjm2zd82k857Yn"
          }
        },
        "id": "RbCtTpyD6kMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply formatting to the dataset\n",
        "dataset = my_dataset.map(formatting_prompts_func, batched = True,)\n",
        "dataset[2]['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n\\nTu es un assistant spÃ©cialisÃ© dans la classification de tickets Ã  partir de leur contenu textuel. Ton objectif est dâ€™analyser la description fournie et de lâ€™associer Ã  lâ€™une des catÃ©gories ci-dessous\\u202f:\\n```\\nDemande de service/Backup #BCS/Autre - Autre\\nDemande de service/Backup #BCS/Demande de renseignement - Demande de renseignement\\nDemande de service/Backup #BCS/Restauration qualifiÃ©e - Restauration qualifiÃ©e\\nDemande de service/Backup #BCS/StratÃ©gie de sauvegarde/CrÃ©ation - CrÃ©ation\\nDemande de service/Backup #BCS/StratÃ©gie de sauvegarde/Modification - Modification\\nDemande de service/Backup #BCS/StratÃ©gie de sauvegarde/Suppression - Suppression\\nDemande de service/Cyber SÃ©curitÃ© #CS2/Bastion/CrÃ©ation-Modification d\\'entrÃ©es - CrÃ©ation-Modification d\\'entrÃ©es\\nIncidents/Backup #BCS/Sauvegarde - Sauvegarde\\nIncidents/Supervision - Supervision\\n```\\n### RÃ¨gles :\\n1. RÃ©ponds uniquement par la catÃ©gorie exacte, sans texte supplÃ©mentaire.\\n2. La catÃ©gorie associÃ©e doit Ãªtre unique.\\n3. Si aucune catÃ©gorie ne correspond, la valeur de \"categorisation\" doit Ãªtre \"unknown\".\\n\\n### Exemple :\\nLa description:\\nBonjourÂ¤ Merci de relancer les sauvegardes FULLÂ¤ si ils ne sont pas repassÃ©es en automatique. Ghislain EnvoyÃ© de mon iPhone DÃ©but du message transfÃ©rÃ©\\n#### Sortie :\\n{\\n  \"categorisation\": \"Incidents/Backup #BCS/Sauvegarde - Sauvegarde\"\\n}\\n\\nAnalyse uniquement la description suivante :\\nBonjourÂ¤ Â¤Â¤ Â¤Â¤ PRTG remonte une alerte sur le core 06: Â¤Â¤ Â¤Â¤ https://monitoring06.antemeta.net/sensor.htm?id=11352&tabid=7 Â¤Â¤ Â¤Â¤\\n<|im_end|>\\n<|im_start|>assistant\\n\\n{\\n  \"categorisation\": \"Incidents/Supervision - Supervision\"\\n}\\n<|im_end|>\\n'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "metadata": {
        "datalore": {
          "node_id": "gegQ0fx6AisDN5CYd45swa",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "W8vzrsa8Lok7QByxI67Xq9"
          }
        },
        "id": "qcGP1SXE6kMa",
        "outputId": "6ceb2390-9734-4054-e21b-b86dce088c79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess function for batch tokenization\n",
        "from functools import partial\n",
        "def preprocess_batch(batch, tokenizer, max_length):\n",
        "    \"\"\"\n",
        "    Tokenizes dataset batch\n",
        "\n",
        "    :param batch: Dataset batch\n",
        "    :param tokenizer: Model tokenizer\n",
        "    :param max_length: Maximum number of tokens to emit from the tokenizer\n",
        "    \"\"\"\n",
        "\n",
        "    return tokenizer(\n",
        "        text=batch[\"text\"],\n",
        "        max_length = max_length,\n",
        "        truncation = True,\n",
        "    )\n",
        "\n",
        "\n",
        "def preprocess_dataset(tokenizer, max_length: int, seed, my_dataset: str):\n",
        "    \"\"\"\n",
        "    Tokenizes dataset for fine-tuning\n",
        "\n",
        "    :param tokenizer (AutoTokenizer): Model tokenizer\n",
        "    :param max_length (int): Maximum number of tokens to emit from the tokenizer\n",
        "    :param seed: Random seed for reproducibility\n",
        "    :param dataset (str): Instruction dataset\n",
        "    \"\"\"\n",
        "    columns_names = my_dataset.column_names\n",
        "    columns_names.append('text')\n",
        "\n",
        "    # Apply preprocessing to each batch of the dataset & and remove initial columns and \"text\" fields\n",
        "    _preprocessing_function = partial(preprocess_batch, max_length = max_length, tokenizer = tokenizer)\n",
        "\n",
        "    my_dataset = my_dataset.map(\n",
        "        _preprocessing_function,\n",
        "        batched = True,\n",
        "        remove_columns = columns_names,\n",
        "    )\n",
        "\n",
        "    # Filter out samples that have \"input_ids\" exceeding \"max_length\"\n",
        "    my_dataset = my_dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
        "\n",
        "    # Shuffle dataset\n",
        "    my_dataset = my_dataset.shuffle(seed = seed)\n",
        "\n",
        "    return my_dataset"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "1rEX405yM88P94v8WDxFct",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "9VI9rr0panAFfG33wng4KX"
          }
        },
        "id": "9MuTqhco6kMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 2048\n",
        "seed = 33\n",
        "preprocessed_dataset = preprocess_dataset(tokenizer, max_length, seed, dataset)"
      ],
      "metadata": {
        "id": "117-uzg1nnms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask'],\n",
              "    num_rows: 3524\n",
              "})"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "metadata": {
        "datalore": {
          "node_id": "d6M7S83MCX00eKYCK8lZVb",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "59eYJaQJw2qp8cxe2Zn1Sb"
          }
        },
        "id": "1yajAKV06kMb",
        "outputId": "cd7e263e-4868-474d-dc59-39b136dafcc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define data collator for batching input during training\n",
        "class TextDataCollator:\n",
        "    def __init__(self, model, tokenizer, max_length=2048):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __call__(self, examples):\n",
        "        # Pad or truncate input_ids and attention_mask\n",
        "        input_ids = [ex[\"input_ids\"][:self.max_length] for ex in examples]\n",
        "        attention_mask = [ex[\"attention_mask\"][:self.max_length] for ex in examples]\n",
        "\n",
        "        # Pad sequences to max_length\n",
        "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "            [torch.tensor(ids) for ids in input_ids],\n",
        "            batch_first=True,\n",
        "            padding_value=0\n",
        "        )\n",
        "\n",
        "        attention_mask = torch.nn.utils.rnn.pad_sequence(\n",
        "            [torch.tensor(mask) for mask in attention_mask],\n",
        "            batch_first=True,\n",
        "            padding_value=0\n",
        "        )\n",
        "\n",
        "        # Add labels (same as input_ids for language modeling)\n",
        "        labels = input_ids.clone()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "22NEPiJ3v8XxWTsmEBq9N5",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "DPidKdHCMYHhzQxTDEFDji"
          }
        },
        "id": "-ln3HKty6kMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "# Set up the training configuration and trainer\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator =  TextDataCollator(model, tokenizer),\n",
        "    train_dataset = preprocessed_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = 2048,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        #max_steps = 30,\n",
        "        num_train_epochs = 1,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "H6uHKWnpQO7kfDr9o7O86i",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "JGLViHEfrvAIM9p7DTvqz9"
          }
        },
        "id": "3B1SdZOq6kMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "\n"
          ],
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 3,524 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 30\n",
            " \"-____-\"     Number of trainable parameters = 68,812,800\n",
            "\n"
          ],
          "output_type": "stream"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 05:27, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.197800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.646600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.502100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.931900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.673800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.553800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.323400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.195500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.911400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.787000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.815500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.782500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.643900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.658900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.517900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.591600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.196200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.442100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.532400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.308400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.398100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.377000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.719700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.237600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.584800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.387000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.250100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.513000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.782000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.400600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "metadata": {
        "datalore": {
          "node_id": "RRJz0Jgp6YItekZZ0B2kt1",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "d8ruNav4nOSqbzt1xxuznU"
          }
        },
        "id": "E8pJpBfK6kMb",
        "outputId": "2c317009-46a5-4fab-cb86-e12d6275243c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Push trained model and tokenizer to Hugging Face Hub (ensure tokens are replaced by placeholders)\n",
        "model.push_to_hub(\"your_hf_hub\", token=\"hf_XXXXXXXX\")\n",
        "tokenizer.push_to_hub(\"you_hf_hub\", token=\"hf_XXXXXXXXXX\")"
      ],
      "metadata": {
        "id": "mgCtrHsSoD4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Save training logs to a CSV file\n",
        "pd.DataFrame(trainer.state.log_history).to_csv(os.path.join(HOME_PATH, \"qwen_log.csv\"))"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "VAQOsoPVzZ3Orsxix3aPd1",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "Ma2TmHFOoGU3kK3g3XpgTn"
          }
        },
        "id": "Lk_Uu7CO6kMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display training logs in DataFrame\n",
        "df = pd.DataFrame(trainer.state.log_history)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>grad_norm</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>epoch</th>\n",
              "      <th>step</th>\n",
              "      <th>train_runtime</th>\n",
              "      <th>train_samples_per_second</th>\n",
              "      <th>train_steps_per_second</th>\n",
              "      <th>total_flos</th>\n",
              "      <th>train_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.1978</td>\n",
              "      <td>13.724114</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.002270</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.6466</td>\n",
              "      <td>15.350007</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.004540</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.5021</td>\n",
              "      <td>4.597202</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.006810</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.9319</td>\n",
              "      <td>1.482393</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.009081</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.6738</td>\n",
              "      <td>1.011267</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.011351</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.5538</td>\n",
              "      <td>1.074024</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.013621</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.3234</td>\n",
              "      <td>0.837895</td>\n",
              "      <td>0.000184</td>\n",
              "      <td>0.015891</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.1955</td>\n",
              "      <td>0.863191</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.018161</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.9114</td>\n",
              "      <td>0.933489</td>\n",
              "      <td>0.000168</td>\n",
              "      <td>0.020431</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7870</td>\n",
              "      <td>0.785147</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.022701</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.8155</td>\n",
              "      <td>0.675480</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.024972</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.7825</td>\n",
              "      <td>0.800122</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>0.027242</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.6439</td>\n",
              "      <td>0.609302</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.029512</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.6589</td>\n",
              "      <td>0.467706</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.031782</td>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.5179</td>\n",
              "      <td>0.465805</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.034052</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.5916</td>\n",
              "      <td>0.617603</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.036322</td>\n",
              "      <td>16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.1962</td>\n",
              "      <td>0.386699</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.038593</td>\n",
              "      <td>17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.4421</td>\n",
              "      <td>0.375297</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.040863</td>\n",
              "      <td>18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.5324</td>\n",
              "      <td>0.394656</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.043133</td>\n",
              "      <td>19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.3084</td>\n",
              "      <td>0.401357</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.045403</td>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.3981</td>\n",
              "      <td>0.401835</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.047673</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.3770</td>\n",
              "      <td>0.328316</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.049943</td>\n",
              "      <td>22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.7197</td>\n",
              "      <td>0.435622</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>0.052213</td>\n",
              "      <td>23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.2376</td>\n",
              "      <td>0.437348</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.054484</td>\n",
              "      <td>24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.5848</td>\n",
              "      <td>0.363941</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.056754</td>\n",
              "      <td>25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.3870</td>\n",
              "      <td>0.379184</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.059024</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.2501</td>\n",
              "      <td>0.341414</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.061294</td>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.5130</td>\n",
              "      <td>0.344101</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.063564</td>\n",
              "      <td>28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.7820</td>\n",
              "      <td>0.332913</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.065834</td>\n",
              "      <td>29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.4006</td>\n",
              "      <td>0.380061</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068104</td>\n",
              "      <td>30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.068104</td>\n",
              "      <td>30</td>\n",
              "      <td>346.473</td>\n",
              "      <td>0.693</td>\n",
              "      <td>0.087</td>\n",
              "      <td>1.459440e+16</td>\n",
              "      <td>0.895429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "      loss  grad_norm  learning_rate     epoch  step  train_runtime  \\\n",
              "0   2.1978  13.724114       0.000040  0.002270     1            NaN   \n",
              "1   2.6466  15.350007       0.000080  0.004540     2            NaN   \n",
              "2   2.5021   4.597202       0.000120  0.006810     3            NaN   \n",
              "3   1.9319   1.482393       0.000160  0.009081     4            NaN   \n",
              "4   1.6738   1.011267       0.000200  0.011351     5            NaN   \n",
              "5   1.5538   1.074024       0.000192  0.013621     6            NaN   \n",
              "6   1.3234   0.837895       0.000184  0.015891     7            NaN   \n",
              "7   1.1955   0.863191       0.000176  0.018161     8            NaN   \n",
              "8   0.9114   0.933489       0.000168  0.020431     9            NaN   \n",
              "9   0.7870   0.785147       0.000160  0.022701    10            NaN   \n",
              "10  0.8155   0.675480       0.000152  0.024972    11            NaN   \n",
              "11  0.7825   0.800122       0.000144  0.027242    12            NaN   \n",
              "12  0.6439   0.609302       0.000136  0.029512    13            NaN   \n",
              "13  0.6589   0.467706       0.000128  0.031782    14            NaN   \n",
              "14  0.5179   0.465805       0.000120  0.034052    15            NaN   \n",
              "15  0.5916   0.617603       0.000112  0.036322    16            NaN   \n",
              "16  0.1962   0.386699       0.000104  0.038593    17            NaN   \n",
              "17  0.4421   0.375297       0.000096  0.040863    18            NaN   \n",
              "18  0.5324   0.394656       0.000088  0.043133    19            NaN   \n",
              "19  0.3084   0.401357       0.000080  0.045403    20            NaN   \n",
              "20  0.3981   0.401835       0.000072  0.047673    21            NaN   \n",
              "21  0.3770   0.328316       0.000064  0.049943    22            NaN   \n",
              "22  0.7197   0.435622       0.000056  0.052213    23            NaN   \n",
              "23  0.2376   0.437348       0.000048  0.054484    24            NaN   \n",
              "24  0.5848   0.363941       0.000040  0.056754    25            NaN   \n",
              "25  0.3870   0.379184       0.000032  0.059024    26            NaN   \n",
              "26  0.2501   0.341414       0.000024  0.061294    27            NaN   \n",
              "27  0.5130   0.344101       0.000016  0.063564    28            NaN   \n",
              "28  0.7820   0.332913       0.000008  0.065834    29            NaN   \n",
              "29  0.4006   0.380061       0.000000  0.068104    30            NaN   \n",
              "30     NaN        NaN            NaN  0.068104    30        346.473   \n",
              "\n",
              "    train_samples_per_second  train_steps_per_second    total_flos  train_loss  \n",
              "0                        NaN                     NaN           NaN         NaN  \n",
              "1                        NaN                     NaN           NaN         NaN  \n",
              "2                        NaN                     NaN           NaN         NaN  \n",
              "3                        NaN                     NaN           NaN         NaN  \n",
              "4                        NaN                     NaN           NaN         NaN  \n",
              "5                        NaN                     NaN           NaN         NaN  \n",
              "6                        NaN                     NaN           NaN         NaN  \n",
              "7                        NaN                     NaN           NaN         NaN  \n",
              "8                        NaN                     NaN           NaN         NaN  \n",
              "9                        NaN                     NaN           NaN         NaN  \n",
              "10                       NaN                     NaN           NaN         NaN  \n",
              "11                       NaN                     NaN           NaN         NaN  \n",
              "12                       NaN                     NaN           NaN         NaN  \n",
              "13                       NaN                     NaN           NaN         NaN  \n",
              "14                       NaN                     NaN           NaN         NaN  \n",
              "15                       NaN                     NaN           NaN         NaN  \n",
              "16                       NaN                     NaN           NaN         NaN  \n",
              "17                       NaN                     NaN           NaN         NaN  \n",
              "18                       NaN                     NaN           NaN         NaN  \n",
              "19                       NaN                     NaN           NaN         NaN  \n",
              "20                       NaN                     NaN           NaN         NaN  \n",
              "21                       NaN                     NaN           NaN         NaN  \n",
              "22                       NaN                     NaN           NaN         NaN  \n",
              "23                       NaN                     NaN           NaN         NaN  \n",
              "24                       NaN                     NaN           NaN         NaN  \n",
              "25                       NaN                     NaN           NaN         NaN  \n",
              "26                       NaN                     NaN           NaN         NaN  \n",
              "27                       NaN                     NaN           NaN         NaN  \n",
              "28                       NaN                     NaN           NaN         NaN  \n",
              "29                       NaN                     NaN           NaN         NaN  \n",
              "30                     0.693                   0.087  1.459440e+16    0.895429  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "metadata": {
        "datalore": {
          "node_id": "t6mGsa5n7g4wz8c4GgUTQy",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "4dhNMEeO6DsbPeaGtKgGLT"
          }
        },
        "id": "6bDWJ8af6kMb",
        "outputId": "ea3ae6d1-83c5-424e-ca7a-c3c4601cd624"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Plot the training loss curve\n",
        "loss = df['loss']\n",
        "step = df['step']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(step, loss, label='Loss', color='blue', linewidth=2)\n",
        "\n",
        "plt.title(\"Loss Curve\", fontsize=16)\n",
        "plt.xlabel(\"Step\", fontsize=14)\n",
        "plt.ylabel(\"Loss\", fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.legend(fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": [
              "iVBORw0KGgoAAAANSUhEUgAAAmUAAAGJCAYAAADL4URDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABfEklEQVR4nO3deXxdRf3/8dckTZsuhLRpaUnTNrULOwoWFJACssi+KntFRQGBH4IgIghl/wICgqigLLKDCsouyiY7StkR7EbThbSliW1DmqYJzfz+mJsmLWnW+7lz78n7+XjkkZu7nDN535PkkzNzZpz3HhERERGJKy92A0RERERERZmIiIhIVlBRJiIiIpIFVJSJiIiIZAEVZSIiIiJZQEWZiIiISBZQUSYiGeOc+45zzjvnxsduS3ucczs45/7knKt0zjU456qdc085545zzuXHbp+IJJOKMhGRVpxzpwMvA0OAnwJ7AN8DZgA3AvtHa5yIJFqf2A0QEckWzrnJwLXAr733p63z8MPOuWuBgWnYTwHwmdfs3SLSis6UiUhWcc4VOOcudc5VpLoOK1JfF7R6Th/n3CXOudnOuXrnXJVz7iXn3NdaPedo59xbzrla59xy59x7zrkTO9j9OcD/gLPbetB7P9t7/25q+xc65z5XVDnnbnfOVbT6ujzVZXuyc+4q51wlsArYPnX/AW1s40bn3JJ1vucfOOfeafX93uqcG9LB9yMiOURnykQk29wBHA5cDrwE7AD8HPgCcHTqOT8FzgDOA94GioBJhC5HUsXZ3cCvgJ8Q/gHdFChe305TY8V2BR7y3ten9TsKzgNeB04A8oF3genAFODRVu3oS/j+7/XeN6buuwI4k5bvZyRwKbClc25H7/1qg/aKSIapKBORrOGc2xI4CrjIe39h6u5/OOdWA5c4565InanaAfiH9/76Vi9/tNXtrwLLvPent7rvHx3sfijQH5jbg2+hPYuBQ1p3WTrn7gJ+7pzb0Hu/PHX3voTi8q7Uc8oJhdhF3vuLW712BqFoPQB4yKjNIpJB6r4UkWwyOfX57nXub/56l9Tn14F9nXOXOee+ljq71NrrwGDn3N3Ouf2dc8U2ze2Sh9oYQ3Y30A/4Vqv7pgDTvff/Tn29J+F39T2pbts+zrk+wL+AGloyE5Ecp6JMRLJJ8xiphevcv2idxy8HpgIHAi8C1c65PzjnhgJ4758nFDqjgL8CS5xzTzvntm5n39XASmBMj7+Ltq37PeG9nwu8QCjESBWP+5E6S5ayUerzLKBxnY8ioMSovSKSYeq+FJFs8r/U5xHA7Fb3j0h9rgZIjbW6ErjSOTeCME3FtcAA4IjUcx4AHnDODSKMFbsSeNI5V+a9b1p3x977z5xz/wT2dM71896v6qCt9RDGgHnvG1rdv74iaX1XWt4F3OycGwN8A+gL3NPq8erU572ApW28vrqN+0QkB+lMmYhkk+dTn49c5/5jUp9fWPcF3vtF3vtbgKeBLdt4vNZ7/xjwO2Bj2j+zdEXq8V+09aBzbmyrs23NY8+2bPV4MbBjO9tvy58JBd4xhDNmL3jvK1o9/hTQBIz23k9r42NOF/cnIllKZ8pEJIa9nXOL1rlvuff+KefcfcCFqXFTrxAG9Z8P3NdqOoqHgXeANwlnj7YB9iYUXjjnLgaGA88BlUAZcBrwtvd+yfoa5b1/wTn3Y+Ba59xmwO3APGAwsDvwfcIVoO8CfwOWE85yTSWMDTsbqO1KEN77GufcI8AphKLxB+s8Pts5dyXwa+fcJoTCtZ7QNbsncIv3/rmu7FNEspPT3IUikinOue8Af1jPw//x3m+ZmptrKuGsUSmhqLqLcPVh8xQRZxLGjE0gdFnOA+4DLvPeNzrn9iMUYVsTxqF9Qrj68nzvfWUn2rkjYcqNrxGuyvwUmAbcSZiqoin1vK8BvwS2ABYAFxNWANjVe1+eek45MAf4QeqMXlv72w94jFBsjWh1JWbr50whFG5bEbpC5wPPAFd47xd09D2JSPZTUSYiIiKSBTSmTERERCQLqCgTERERyQIqykRERESygIoyERERkSygokxEREQkC+T8PGVDhw715eXlsZshIiIi0qE33nijyns/rK3Hcr4oKy8vZ9q0aet9/OOPP2bkyJEZbFHvonztKFs7ytaW8rWjbG1lIl/n3Nz1PZb47ssVK1bEbkKiKV87ytaOsrWlfO0oW1ux8018USYiIiKSCxJflJWVlcVuQqIpXzvK1o6ytaV87ShbW7HzTXxRVl9fH7sJiaZ87ShbO8rWlvK1o2xtxc435wf6d6SqqoohQ4bEbkZiKV87ytaOsrWlfO1ka7aNjY0sWLAgelHTU42NjSxevLjH2yksLKSsrIyCgoIuvS7xRZmIiIjYWrBgARtssAHl5eU452I3p9vq6+spLCzs0Ta891RXV7NgwQLGjh3bpdcmvvuypKQkdhMSTfnaUbZ2lK0t5WsnW7Otr6+npKQkpwsygD59en6uyjlHSUlJt84aJr4oGzBgQOwmJJrytaNs7ShbW8rXTjZnm+sFGUBeXnrKou5mkfiibP78+bGbkGjK146ytaNsbSlfO8rWVkNDQ9T9J74oExEREckFiS/K+vfvH7sJiaZ87ShbO8rWlvK1o2y7rry8nKeffrpTz01X92V3Jb4oGzVqVOwmAPD003D//eB97JakV7bkm0TK1o6ytaV87ShbW3379o26/8QXZTNmzIjdBGpr4aCD4Kij4MILk1WYZUO+SaVs7ShbW8rXjrJNj1WrVnH66adTWlpKaWkpp59+OqtWraK+vp6qqir2339/iouLGTJkCDvvvDNNTU0AXHnllYwcOZINNtiATTbZhGeeeSat7dI8ZRnw5JNQVxduX3xx+HzhhZCAC1VERETWkqm/bT05wXHZZZfx2muv8fbbb+Oc46CDDuLSSy/lvPPO45prrqGsrIwlS5YA8Nprr+GcY/r06fz617/m9ddfp7S0lIqKClavXp2m7yZI/JmybPDgg+HzN74B+fmhMEvaGTMREZFccc8993DBBRew0UYbMWzYMKZOncpdd90FQEFBAQsXLmTu3LkUFBSw884745wjPz+fVatW8cEHH9DY2Eh5eTnjxo1La7sSX5RNnDgx6v7r6+Gxx8Lt3/4W7rknWYVZ7HyTTNnaUba2lK+dXMjW+8x89ERlZSVjxoxZ8/WYMWOorKyksLCQn/zkJ4wfP5699tqLL3zhC1xxxRUAjB8/nuuuu44LL7yQjTbaiCOPPJLKysqeNWQdiS/KYs/p8vTTYUzZl74EX/gCHHFEsgqz2PkmmbK1o2xtKV87yjY9SktLmTt37pqv582bR2lpKQ0NDWywwQZcc801fPTRRzz66KNce+21a8aOHX300bz00kvMnTsX5xw//elP09quxBdlK1eujLr/v/wlfD7ssJb7klSYxc43yZStHWVrS/naUbbd09jYSH19/ZqPo446iksvvZQlS5ZQVVXFxRdfzLHHHktTUxOPPfYYs2bNwntPUVER+fn55OfnM336dJ599llWrVpFYWEh/fv3Jz8/P63tTHxRFlNjIzz8cLh96KFrP5akwkxERCSb7bvvvvTv33/NR319PZMmTWLrrbdmq622Ytttt+XnP/85ADNnzmSPPfZg0KBB7LDDDpx88snsuuuurFq1inPOOYehQ4cyYsQIPvnkEy6//PK0ttP5HK8EJk2a5KdNm7bex1euXBltsr1nnoE99oBNN4UPP2z7OX/8IxxzDKxeDRdckHtXZcbMN+mUrR1la0v52snWbD/88EM222yz2M3osaamprRNILu+TJxzb3jvJ7X1msSfKatrnosiguarLtc9S9baumfMpk7NrTNmMfNNOmVrR9naUr52lK2t5vnIYkl8UVZdXR1lv01N8Ne/htutx5O1pXVhdskluVWYxcq3N1C2dpStLeVrR9na+uyzz6LuX5PHGnntNVi0CMrLYZttOn7+EUeEz8ccEwozgIsuyq2uTBEREem+xBdlQ4cOjbLf1l2XnS2scrEwi5Vvb6Bs7ShbW8rXjrK11adP3LIo8UVZYWFhxvfpfctUGO2NJ2tLrhVmMfLtLZStHWVrS/nayeZsvfe4bP1j1Unpan93L6JM/JiyBQsWZHyfb70FFRUwYgTssEPXX59LY8xi5NtbKFs7ytaW8rWTrdkWFhZSXV3d7WIkWzQ2NvZ4G957qquru1VAJ/5MWQzNZ8kOOQS6e2Vtrp0xExGR3qusrIwFCxasWcQ7VzU2NlJQUNDj7RQWFlJWVtbl12WsKHPOjQLuBEYATcDvvffXr/OcXYGHgTmpu/7ivb+4J/sdOHBgT17eLc3jyTq66rIjuVCYxci3t1C2dpStLeVrJ1uzLSgoYOzYsbGb0WMff/wxI0eOjLb/jE0e65zbGNjYe/+mc24D4A3gYO/9B62esytwlvd+/85ut6PJYzPdx/3hh7D55jBkSLj6Mg0F91oTzJ5/fnYVZkkYQ5CtlK0dZWtL+dpRtrYykW9WTB7rvV/ovX8zdftT4EPAvBydOXOm9S7W0nyW7KCD0lOQwefHmN1xR3q2mw6Zzrc3UbZ2lK0t5WtH2dqKnW+UMWXOuXJgG+BfbTy8g3PuHaCScNbsP228/gTgBAj92DNmzADCpcKFhYVrBkIOHDgQ7/2ax/Py8hg/fjzz5s2jvr4egDFjxlBTU8PSpUsBGDZsGAUFBVRWVgIwaNAghg8fzuzZswHIz89n3LhxVFRU0NDQAEB5eTnLli1j2bJl3HffaKCQvfeuY8aM0I6ioiJKSkqYMyf0yjaf5p0zZ86aQYVjx46lurqampoaAEaMGIH3nsWLFwOw227FXHXVEM48sw+33rqCXXddQnl5ObNnz2b16tUAjBs3jsWLF1NbWwtAaWkpjY2Na/r4Bw8eTFFREXPnzgVCn/fo0aOZNWvWmlmMJ0yYQGVlJStWrKA53/r6eqqqqgAoKSlhwIABzJ8/H4Dly5cDrMkYYOLEicyfP3/NwrmjRo2irq5uzaSHbb1PpaWla34YMvE+AQwfPhznHIsWLUrb+1RcXExxcTEVFRUA9O3bt9vvU3Pm6Xif+vfvz6hRo/Q+pd6n2tpaGhoa0vI+pfPnKSnvU1VVVdb9PCXlfWpoaFiz32z5eUrS+1RXV0ddXZ3pz1N7Mr72pXNuEPA8cJn3/i/rPFYENHnva51z+wLXe+8ntLe9jrovZ82axfjx49PQ8o599BGMGweDBsGSJZDuK5cXLoTSUhg4EJYuTd+ZuJ7IZL69jbK1o2xtKV87ytZWJvLNiu7LVEMKgAeBe9YtyAC89zXe+9rU7SeAAudcj2bKy+TB27ys0v77p78gA9h4Y9hkE1ixAtqpQzNKvxzsKFs7ytaW8rWjbG3FzjdjRZkLI+duBT703l+7nueMSD0P59z2qfb1aKGvefPm9eTlXdKZBch7arfdwufnnrPbR1dkMt/eRtnaUba2lK8dZWsrdr6ZPFO2EzAF+Lpz7u3Ux77OuZOccyelnvNN4P3UmLJfAUf6HvavNvf5WqushFdfDWfI9tnHbj/ZVpRlKt/eSNnaUba2lK8dZWsrdr4ZG+jvvX8JaPc6U+/9r4FfZ6ZF6dXcdfmNb4QxZVZ23TV8fvllWLUK+vWz25eIiIhkTuKXWRozZkxG9tM8i39PJ4ztyEYbwRZbwMqV8O9/2+6rMzKVb2+kbO0oW1vK146ytRU738QXZc2X8FqqqoLnn4c+fcIgf2vZ1IWZiXx7K2VrR9naUr52lK2t2PkmvihrnjfE0iOPhNn2d98dBg82311WFWWZyLe3UrZ2lK0t5WtH2dqKnW/ii7JMaO66tLzqsrVddgmfX30VNOZTREQkGRJflA0bNsx0+zU18NRTYS3Kgw823dUaJSWw9dZhoP+rr2Zmn+tjnW9vpmztKFtbyteOsrUVO9/EF2UFxtPeP/44NDTAzjuHQfiZki1dmNb59mbK1o6ytaV87ShbW7HzTXxR1rz2lJXmCWOtr7pcV7YUZdb59mbK1o6ytaV87ShbW7HzTXxRZqmuDv72t3D7kEMyu+/Jk0OX6b/+FdohIiIiuS3xRdkgw5lc//73UBBtvz2MGmW2mzYNHgzbbAONjfDKK5ndd2uW+fZ2ytaOsrWlfO0oW1ux8018UTZ8+HCzbWf6qst1ZUMXpmW+vZ2ytaNsbSlfO8rWVux8E1+UzZ4922S7DQ3w6KPhdm8uyqzyFWVrSdnaUr52lK2t2Pkmviiz8uyzsHw5bLUVTJgQpw077wz5+fD661BbG6cNIiIikh6JL8ry8/NNttt81WWss2QARUXw5S/DZ5/BSy/FaYNVvqJsLSlbW8rXjrK1FTvfxBdl48aNS/s2V6+Ghx4KtzM9Fca6YndhWuQrgbK1o2xtKV87ytZW7HwTX5RVVFSkfZsvvhgWIR8/HrbcMu2b75LYRZlFvhIoWzvK1pbytaNsbcXON/FFWUNDQ9q32XzV5WGHhbnCYtppJ+jTB954I4xxyzSLfCVQtnaUrS3la0fZ2oqdb+KLsnRraoo/FUZrgwbBdtuFdr34YuzWiIiISHclvigrLy9P6/Zefx0+/hjKykIxlA2auzD/+c/M7zvd+UoLZWtH2dpSvnaUra3Y+Sa+KFu2bFlat9f6LFnsrstmMceVpTtfaaFs7ShbW8rXjrK1FTtfFWVd4H28Bcjbs+OOUFAAb70FS5dmdt+xD+AkU7Z2lK0t5WtH2dqKnW/ii7J0eu89mD0bNtooDLDPFgMGwFe/GorGF16I3RoRERHpjsQXZelcx6r5LNnBB4eZ9LNJrC7M2OuEJZmytaNsbSlfO8rWVux8E1+UuTQO/Mqmqy7XFasoS2e+sjZla0fZ2lK+dpStrdj5Jr4oW7RoUVq2M2MGvP8+FBe3FEDZ5KtfhX794N13w8S2mZKufOXzlK0dZWtL+dpRtrZi55v4oixdms+SHXAA9O0bty1tKSwMA/4Bnn8+bltERESk6xJflBUVFaVlO9l41eW6YnRhpitf+Txla0fZ2lK+dpStrdj5Jr4oKykp6fE25s2DadNg4EDYa680NMrIrruGz5ksytKRr7RN2dpRtraUrx1layt2vokvyubMmdPjbTR3Xe67L/Tv3+PNmdl++9C+Dz6ATz7JzD7Tka+0TdnaUba2lK8dZWsrdr6JL8rSIZuvumytX7+W+dNiLLkkIiIi3Zf4oqygoKBHr1+0CF56KQzu32+/NDXKUKbHlfU0X1k/ZWtH2dpSvnaUra3Y+Sa+KBs7dmyPXv/ww2Gm/L32gg02SFOjDGW6KOtpvrJ+ytaOsrWlfO0oW1ux8018UdbT/uENN4Rtt83uqy5bmzQpXJAwfTpUVtrvL3b/e5IpWzvK1pbytaNsbcXON/FFWWNjY49ef+SR8MYbcNxxaWqQsYIC2HnncDsT48p6mq+sn7K1o2xtKV87ytZW7HwTX5SlSy6tbBFrySURERHpvsQXZbH7h2PIZFHWG/PNFGVrR9naUr52lK2t2Pkmviirrq6O3YSM22YbKCqC2bNh/nzbffXGfDNF2dpRtraUrx1layt2vokvympqamI3IeP69IHJk8Nt67NlvTHfTFG2dpStLeVrR9naip1v4ouy3irGkksiIiLSfYkvykaMGBG7CVE0jyuzvgKzt+abCcrWjrK1pXztKFtbsfNNfFHmvY/dhCi++EUoLoaKivBhpbfmmwnK1o6ytaV87ShbW7HzTXxRtnjx4thNiCI/H3bZJdy27MLsrflmgrK1o2xtKV87ytZW7HwTX5T1ZpqvTEREJHckvigrLi6O3YRoWhdlVmdke3O+1pStHWVrS/naUba2YueroizBttwSSkpgwYIwZ5mF3pyvNWVrR9naUr52lK2t2PkmviirsBzlnuXy8uynxujN+VpTtnaUrS3la0fZ2oqdb+KLst5O48pERERyQ+KLsr59+8ZuQlTW48p6e76WlK0dZWtL+dpRtrZi5+tiz8nRU5MmTfLTpk2L3Yys5T2MGAGffAIffgibbhq7RSIiIr2Xc+4N7/2kth5L/Jmy2VYj3HOEcy3jyixm9+/t+VpStnaUrS3la0fZ2oqdb+KLstWrV8duQnSW48qUrx1la0fZ2lK+dpStrdj5Jr4ok7XXwczx3moREZHEytiYMufcKOBOYATQBPzee3/9Os9xwPXAvkAd8B3v/ZvtbbejMWWrV68mPz+/h63Pbd7DyJGwcCG8/z5ssUX6tq187ShbO8rWlvK1o2xtZSLfbBlT9hlwpvd+M+CrwCnOuc3Xec4+wITUxwnAjT3daex1rLKBc3ZdmMrXjrK1o2xtKV87ytZW7HwzVpR57xc2n/Xy3n8KfAiMXOdpBwF3+uA1oNg5t3FP9ltbW9uTlyeGVVGmfO0oWzvK1pbytaNsbcXON8qYMudcObAN8K91HhoJzG/19QI+X7hJN7QeV9bUFLUpIiIi0oY+md6hc24Q8CBwuve+Zt2H23jJ5wa9OedOIHRvUlZWxowZMwAYOnQohYWFLFiwAICBAwey8cYbr3k8Ly+P8ePHM2/ePOrr6wEYM2YMNTU1LF26FIBhw4ZRUFBAZWUlAIMGDWL48OFrLpPNz89n3LhxVFRU0NDQAEB5eTnLli1j2bJlAAwfPhznHIsWLQKgqKiIkpIS5syZA0BBQQFjx45lzpw5NDY2AjB27Fiqq6upqQmRjBgxAu/9mlOpxcXFFBcXr1kCom/fvpSXlzN79uw1V4uMGzeOxYsXr6n0S0tLaWxsZMmSJalxZeP4+ON8Hnusgk03baCwsJDRo0cza9YsmlKV2oQJE6isrGTFihU051tfX09VVRUAJSUlDBgwgPnz56/JFFiTMcDEiROZP38+K1euBGDUqFHU1dVRXV293veptLSUmTNn9vr3CWDw4MEUFRXR0NDAjBkz0vI+9e/fn1GjRul9Sr1P/fr1o6GhIS3v09y5cwH0PrV6nxoaGli0aFFW/Twl5X0qLi5es99s+XlK0vs0cOBA6urqTH+e2pPRyWOdcwXAY8DfvffXtvH474B/eu/vS309HdjVe79wfdvsaKD/0qVLGTx4cI/bngTHHQd33gm//CWcfnp6tql87ShbO8rWlvK1o2xtZSLfrBjon7qy8lbgw7YKspRHgG+74KvA8vYKss5orsLFZlyZ8rWjbO0oW1vK146ytRU730x2X+4ETAHec869nbrvXGA0gPf+JuAJwnQYswhTYnw3g+1LvOaZ/Z9/HlavBl1VLSIikj0yVpR571+i7TFjrZ/jgVPSuV+d5m1RXh4+KirgnXdg2217vk3la0fZ2lG2tpSvHWVrK3a+iZ/Rv6ioKHYTskq6uzCVrx1la0fZ2lK+dpStrdj5Jr4oa76SQ4J0F2XK146ytaNsbSlfO8rWVux8E1+Uydqai7IXXoDUVcUiIiKSBRJflBUWFsZuQlYpK4OvfAU+/RSuvrrn21O+dpStHWVrS/naUba2Yueb0XnKLHQ0T5l83gsvwC67wIABMHMmlJbGbpGIiEjvkBXzlMUya9as2E3IOpMnwyGHQF0dnH9+z7alfO0oWzvK1pbytaNsbcXON/FFWZMWemzTlVdCnz7whz/A2293fzvK146ytaNsbSlfO8rWVux8E1+USdsmTIBTTwXv4ayzwmcRERGJJ/Fjyrz3hBWeZF3/+x+MHw9Ll8Jjj8F++3V9G8rXjrK1o2xtKV87ytZWJvLt1WPKmldpl88bMqRlTNlZZ0FjY9e3oXztKFs7ytaW8rWjbG3FzjfxRdkKTcbVrlNOCWfL/vtfuPnmrr9e+dpRtnaUrS3la0fZ2oqdb+KLMmlf375h0D/A1KmwfHnc9oiIiPRWiS/KysrKYjch6x1yCOy8M1RVweWXd+21yteOsrWjbG0pXzvK1lbsfBNflNXX18duQtZzDq69Nty+7jqYM6fzr1W+dpStHWVrS/naUba2Yueb+KKsqqoqdhNywqRJcMwx0NAAP/tZ51+nfO0oWzvK1pbytaNsbcXON/FFmXTe5ZdDYSH88Y/w2muxWyMiItK7JL4oKykpid2EnDF6NPz4x+H2j3/cuQllla8dZWtH2dpSvnaUra3Y+Sa+KBswYEDsJuSUc86BjTaCV1+FP/+54+crXzvK1o6ytaV87ShbW7HzTXxRNn/+/NhNyCkbbACXXBJun3MOdDTmUfnaUbZ2lK0t5WtH2dqKnW/iizLpuu99D7bYIlyFecMNsVsjIiLSOyS+KOvfv3/sJuScPn3gmmvC7csuC/OXrY/ytaNs7ShbW8rXjrK1FTvfxC9ILt23997w97/DqafqjJmIiEg69OoFyWfMmBG7CTnr6qshLw9uvDGsjdkW5WtH2dpRtraUrx1layt2vokvyqT7ttwSvv99WL0azj47dmtERESSTUWZtOvii2HQIHj0UXj22ditERERSS6NKZMOXX45nHcefOlLMG0a5OfHbpGIiEhu6tVjymLPOZIEZ5wBo0bB22/DXXet/ZjytaNs7ShbW8rXjrK1FTvfxBdlK1eujN2EnNe/fzhbBnDuubBiRctjyteOsrWjbG0pXzvK1lbsfBNflEl6HH00TJoECxeGqzJFREQkvRJflI0aNSp2ExIhLw+uvTbcvuoqqKwMt5WvHWVrR9naUr52lK2t2Pkmviirq6uL3YTE2HlnOPRQqKuDn/883Kd87ShbO8rWlvK1o2xtxc438UVZdXV17CYkypVXQkEB3H57GPivfO0oWzvK1pbytaNsbcXON/FFmaTX+PFwyingPZx5ZvgsIiIiPZf4omzo0KGxm5A4558PgweHyWSffro0dnMSS8euHWVrS/naUba2Yueb+KKssLAwdhMSZ8iQMNM/wKmnDuKSS3TGzIKOXTvK1pbytaNsbcXON/FF2YIFC2I3IZFOOQV+8QtwznPBBXDUUaDpc9JLx64dZWtL+dpRtrZi55v4okxsOAdnnQU33VTJBhvAH/8IkyfDxx/HbpmIiEhuSnxRNnDgwNhNSLT99oNXX4WxY8O6mNttB6+/HrtVyaBj146ytaV87ShbW7HzTfyC5N57nHMZbFHv0pxvVRUcdhi88AIUFoYpM444InbrcpuOXTvK1pbytaNsbWUi3169IPnMmTNjNyHRmvMdOhSeegq+/32or4cjj4QLLoCmpsgNzGE6du0oW1vK146ytRU738QXZZI5ffvC738P110XlmW65BI4/PC1FzAXERGRtiW+KMvLS/y3GNW6+ToHP/oRPPEEbLghPPggfO1rMH9+pAbmMB27dpStLeVrR9naip1v4seUSTz//S8ccADMmgXDh8NDD8FXvxq7VSIiIvH06jFl8+bNi92ERGsv3003hX/9C77+dVi8GHbdFe6+O3Nty3U6du0oW1vK146ytRU738QXZfX19bGbkGgd5TtkCDz5JPzwh7BqFUyZAj/7mS4A6Awdu3aUrS3la0fZ2oqdb+KLMomvoAB++1v4zW8gPx+uuAIOOQQ+/TR2y0RERLJH4seUrVq1in79+mWwRb1LV/N9+mn41rdg2TLYait45BEoLzdrXk7TsWtH2dpSvnaUra1M5Nurx5TV1NTEbkKidTXfPfaAf/8bNtkE3nsPtt8eXnrJqHE5TseuHWVrS/naUba2Yueb+KJs6dKlsZuQaN3Jd8IEeO012GsvWLIE9t4bKirS37Zcp2PXjrK1pXztKFtbsfNNfFEm2am4GB5/HA4+OEwue8opkOM96SIiIj2S+KJs2LBhsZuQaD3Jt08fuPHGMMnsE0/AAw+ksWEJoGPXjrK1pXztKFtbsfNNfFFWUFAQuwmJ1tN8R4yAK68Mt087LVwAIIGOXTvK1pbytaNsbcXON2NFmXPuNufcJ86599fz+K7OueXOubdTHxekY7+VlZXp2IysRzry/cEPYMcdYdGiMIeZBDp27ShbW8rXjrK1FTvfHhdlzrnOlpW3A3t38JwXvfdfSn1c3LOWSa7Iy4Pf/S50Z950E7z6auwWiYiIZF6XijLn3GnOucNafX0rsNI5N905t0l7r/XevwD8r3vN7L5BgwZlepe9Srry3XJLOPvscPuEE6CxMS2bzWk6du0oW1vK146ytRU73z5dfP5pwPcAnHOTgcOBo4HDgGuA/XvYnh2cc+8AlcBZ3vv/tPUk59wJwAkAZWVlzJgxA4ChQ4dSWFjIggULABg4cCDDhw9f83heXh7jx49n3rx5a5ZSGDNmDDU1NWsugx02bBgFBQVrTmEOGjSI4cOHM3v2bADy8/MZN24cFRUVNDQ0AFBeXs6yZctYlhoQNXz4cJxzLFq0CICioiJKSkqYM2cOEPqsx44dy5w5c2hMVR9jx46lurp6zRwpI0aMwHvP4sWLASguLqa4uJiK1NwRffv2pby8nNmzZ7N69WoAxo0bx+LFi6mtrQWgtLSUxsZGlixZAsDgwYMpKipi7ty5ABQWFjJ69GhmzZpFU2rdowkTJlBZWcmKFStozre+vp6qqioASkpKGDBgAPPnzwdYM8lec8YAEydOZP78+axcuRKAUaNGUVdXR3V19Xrfp9LSUo44YhZ33z2G99/vy9VXwzHH9O73qaamhtra2rS8T/3792fUqFFpeZ9mzpwJ5PbP0wYbbEBDQ0PW/Twl5X1qamoiLy8vq36ekvI+DRw4cM1+s+XnKUnv05AhQ6irqzP9eWpPl2b0d86tBDbx3s9zzv0CKPHef885txmh63FoB68vBx7z3m/ZxmNFQJP3vtY5ty9wvfd+Qkdt6mhG/xkzZjBx4sSONiPdlO58n3oqzF9WWAjvvw/jxqVt0zlHx64dZWtL+dpRtrYykW86Z/SvAZqvF90TeCZ1uxEo7F7zAu99jfe+NnX7CaDAOddukSfJs+eecMwxUF8fFjHX3GUiItJbdLUo+wdwc2os2Xjgb6n7twDm9KQhzrkRzjmXur19qm3VPdkmhNO5Ysci32uvhSFDwlmze+9N++Zzho5dO8rWlvK1o2xtxc63q92XRcBlwGjgRu/9k6n7LwJWee8vb+e19wG7AkOBxcBUoADAe3+Tc+5U4IfAZ8BK4Mfe+1c6alNH3ZeSm267DY4/HoYNg//+NxRpIiIiua697ssuFWXZqKOirKKigvLy8sw1qJexytd72HVXeOGFUJzdckvad5H1dOzaUba2lK8dZWsrE/mmbUyZc27z1lNfOOf2dM7d7Zz7mXMuK8+pNl+BIjas8nUuzF3Wty/cemsoznobHbt2lK0t5WtH2dqKnW9Xx5TdCmwD4JwrAx4GhgCnAJemt2nS2226acsM/yeeCKtWxW2PiIiIpa4WZZsBb6Zufwv4l/d+X2AKcFQ6G5YuOs1ryzrfc86BiRPDuLLmNTJ7Cx27dpStLeVrR9naip1vV4uyfKD53N7uwBOp27OB4elqVDot0wrXpqzzLSwM3ZgAl10GreYATDwdu3aUrS3la0fZ2oqdb1eLsveBHzrndiYUZU+m7h8JVKWzYekSO+Cky0S+u+4K3/kONDTASSf1nrnLdOzaUba2lK8dZWsrdr5dLcp+CvwA+Cdwn/f+vdT9BwL/TmO7RNZy9dUwdCg89xzccUfs1oiIiKRfl4qy1KLiw4Ch3vvvtXrod4Q5xrLO8OFZ2auaGJnKt6QkTCoLcNZZUJWV52XTS8euHWVrS/naUba2Yufb1TNleO9XAyudc1s657ZwzhV67yu8958YtK/HUosEiJFM5nvssbD77lBdDWeembHdRqNj146ytaV87ShbW7Hz7eo8ZX1SC5EvBd4B3gOWOueucs4VWDSwpxYtWhS7CYmWyXydgxtvhH794M474ZlnOn5NLtOxa0fZ2lK+dpStrdj5dvVM2VXAscBJwERgAqHbcgrwf+ltmsjnTZgA558fbp90Uli4XEREJAm6WpQdDRzvvb/Dez879XE78H3gmLS3Lg2KiopiNyHRYuT7k5/A5pvDrFlhmoyk0rFrR9naUr52lK2t2Pl2tSjbkDAn2bpmA8U9bo2BkpKS2E1ItBj59u3bMnfZlVfCBx9kvAkZoWPXjrK1pXztKFtbsfPtalH2DnBaG/f/KPVY1pkzZ07sJiRarHy/9jX4wQ+gsTEswdTUFKUZpnTs2lG2tpSvHWVrK3a+XS3KzgaOc87NcM7d4Zy73Tk3nTDO7Kz0N09k/a68EoYPh5deCouWi4iI5LLuzFM2EfgzMAgoSt3+Bm2fQYuuoCArLwpNjJj5Dh4M110Xbp99NiTtoiQdu3aUrS3la0fZ2oqdr/NpWLPGOfdF4E3vfX7Pm9Q1kyZN8tOmTcv0biVLeA/77AN//ztssQX87W8walTsVomIiLTNOfeG935SW491efLYXBO7fzjpYufrHNx2G2y2GfznP7DDDvDuu1GblDaxs00yZWtL+dpRtrZi55v4oqyxsTF2ExItG/ItLYWXX4add4aPPw6fn302dqt6LhuyTSpla0v52lG2tmLnm/iiTHqHwYPhH/+Ab30Lampg773h3ntjt0pERKTzOjWmzDn3SAdPKQJ2zsYxZY2NjdEH7iVZtuXb1BQWLP/lL8PXV1wRLgLIxeXisi3bJFG2tpSvHWVrKxP5pmNMWXUHH3OAO3ve1PSrrq6O3YREy7Z88/Lg2mvDh3Nwzjlw6qmwenXslnVdtmWbJMrWlvK1o2xtxc63T2ee5L3/rnVDrNTU1DBixIjYzUisbM33jDOgrAyOPRZ++1uorAzdmf37x25Z52VrtkmgbG0pXzvK1lbsfDWmTBLrW9+Cp56C4mJ46CHYfXeoqordKhERkbYlvijTfxS2sj3fyZPDlZmjR8Orr8KOO8JHH8VuVedke7a5TNnaUr52lK2t2PkmvihLx+S4sn65kO/mm4eC7ItfhJkzw1xmuTDfcC5km6uUrS3la0fZ2oqdb+KLssWLF8duQqLlSr6lpfDCC7DHHvDJJ7DLLvDEE7Fb1b5cyTYXKVtbyteOsrUVO9/EF2UizYqK4PHHYcoUqKuDAw/UQuYiIpI9El+UFRcXx25CouVavn37wh13wLnnhmkyvv99mDo1rKGZbXIt21yibG0pXzvK1lbsfFWUSY/kYr7OwWWXwY03hnnNLr4Yjj8esm31klzMNlcoW1vK146ytRU738QXZRUVFbGbkGi5nO9JJ8Ff/xrmLvvDH0J3Zm1t7Fa1yOVss52ytaV87ShbW7HzTXxRJtKeAw+E556DoUPhySdhr71yc/Z/ERHJfYkvyvr27Ru7CYmWhHy/8hV45ZVwhearr8L998duUZCEbLOVsrWlfO0oW1ux8+3UguTZrKMFyUU667bbwtiyCRPggw+gT6cWIRMREem8dCxInrNmz54duwmJlqR8p0yBcePCBLP33BO7NcnKNtsoW1vK146ytRU738QXZas1QMhUkvItKAjTY0C4IjP21ZhJyjbbKFtbyteOsrUVO9/EF2UiXXHUUbDJJmF9zDvuiN0aERHpTRI/pmz16tXk5+dnsEW9SxLzve8+OProsIj5zJlhwtkYkphttlC2tpSvHWVrKxP59uoxZbHXsUq6JOZ7+OGwxRYwb14Y/B9LErPNFsrWlvK1o2xtxc438UVZbTbNBppAScw3Px8uvDDcvvRSqK+P044kZpstlK0t5WtH2dqKnW/iizKR7jj0UNh6a/j4Y7j55titERGR3iDxRVlpaWnsJiRaUvPNy4OLLgq3L78cVq7MfBuSmm02ULa2lK8dZWsrdr6JL8oaY89rkHBJzvegg2DbbWHRIrjppszvP8nZxqZsbSlfO8rWVux8E1+ULVmyJHYTEi3J+ToX5isDuOIKWLEis/tPcraxKVtbyteOsrUVO9/EF2UiPbHvvrD99vDJJ/Cb38RujYiIJFnii7LBgwfHbkKiJT3f1mfLrroKPv00c/tOerYxKVtbyteOsrUVO9/EF2VFRUWxm5BovSHfvfaCnXaC6mr41a8yt9/ekG0sytaW8rWjbG3FzjfxRdncuXNjNyHRekO+rc+WXX01LF+emf32hmxjUba2lK8dZWsrdr6JL8pE0mG33WCXXWDZMrjuutitERGRJEp8UVZYWBi7CYnWW/Jtfbbs2mth6VL7ffaWbGNQtraUrx1layt2vokvykaPHh27CYnWm/KdPBn22ANqauCaa+z315uyzTRla0v52lG2tmLnm/iibNasWbGbkGi9Ld/mWf6vvx6qqmz31duyzSRla0v52lG2tmLnm7GizDl3m3PuE+fc++t53DnnfuWcm+Wce9c5t2069tvU1JSOzch69LZ8d9wR9t4bamvDoH9LvS3bTFK2tpSvHWVrK3a+mTxTdjuwdzuP7wNMSH2cANyYgTaJdFnz2LIbboDFi+O2RUREkiNjRZn3/gXgf+085SDgTh+8BhQ75zbu6X4nTJjQ001IO3pjvtttBwccAHV1YUJZK70x20xRtraUrx1layt2vtk0pmwkML/V1wtS9/VIZWVlTzch7eit+TaPLfvtb2HhQpt99NZsM0HZ2lK+dpStrdj59om697W5Nu7zbT7RuRMIXZyUlZUxY8YMAIYOHUphYSELFiwAYODAgdTW1q55PC8vj/HjxzNv3jzq6+sBGDNmDDU1NSxNzXEwbNgwCgoK1rwxgwYNYvjw4cyePRuA/Px8xo0bR0VFBQ0NDQCUl5ezbNkyli1bBsDw4cNxzrFo0SIgzBBcUlLCnDlzACgoKGDs2LHMmTNnzYr0Y8eOpbq6mpqaGgBGjBiB957Fqf6x4uJiiouLqaioAKBv376Ul5cze/ZsVq9eDcC4ceNYvHgxtbW1AJSWltLY2LhmgdXBgwdTVFS0ZnK8wsJCRo8ezaxZs9b0o0+YMIHKykpWpFbfLisro76+nqrUqPaSkhIGDBjA/Pmhfl6+fDkjR45ckzHAxIkTmT9/PitXrgRg1KhR1NXVUV1dvd73qbS0lJkzZ+bM+zRwYA177rkxTz21ARddtIof/3iuyfu0YsWKtLxP/fv3Z9SoUb3ufVrfz1NtbS3Dhg3Lup+npLxPVVVV5OfnJ/b3Xsz3aenSpWvamS0/T0l6n+rq6hg8eLDpz1N7nPdt1j0mnHPlwGPe+y3beOx3wD+99/elvp4O7Oq9b/c8xKRJk/y0adPW+/iMGTOYOHFij9ot69eb833vPdh6a+jbF2bPhrKy9G6/N2drTdnaUr52lK2tTOTrnHvDez+prceyqfvyEeDbqaswvwos76gg64yydP+llLX05ny32goOPxwaGuDyy9O//d6crTVla0v52lG2tmLnm8kpMe4DXgU2cc4tcM4d75w7yTl3UuopTwAfAbOAm4GT07Hf5tOLYqO35zt1apjt/5ZbIN1LpvX2bC0pW1vK146ytRU730xefXmU935j732B977Me3+r9/4m7/1Nqce99/4U7/047/1W3vv190l2QZX1DJ+9XG/Pd/PN4aijoLERLr00vdvu7dlaUra2lK8dZWsrdr7Z1H0pkpOmToW8PPjDH8LYMhERke5IfFFWUlISuwmJpnxh4kSYMgVWr07v2TJla0fZ2lK+dpStrdj5Jr4oGzBgQOwmJJryDc4/H/Lz4c47IXXldI8pWzvK1pbytaNsbcXON/FFWfN8JWJD+QbjxsF3vgNNTS0Ty/aUsrWjbG0pXzvK1lbsfBNflIlkys9/DgUFcO+9YQ4zERGRrkh8Uda/f//YTUg05duivByOPx68hz33hNdf79n2lK0dZWtL+dpRtrZi55vRGf0tdDSjv0gm1dTAoYfCM89A//5wzz1wyCGxWyUiItkiV2b0N9F6zStJP+W7tqIieOIJ+N73YOVKOOwwuOaacPasq5StHWVrS/naUba2Yueb+KJMJNP69g0z/F9+eSjGzjoLTjkFPvssdstERCSbqSgTMeAc/OxncP/90K8f3HgjHHggfPpp7JaJiEi20pgyEWMvvwwHHQTV1bD11vD446A1hUVEeqdePaYs9pwjSad8O7bTTvDaa2Hm/3ffha98Bd56q+PXKVs7ytaW8rWjbG3FzjfxRdnKlStjNyHRlG/njB8Pr74KkydDZSXsvDM89lj7r1G2dpStLeVrR9naip1v4osykWwxZAj84x9w7LGwYkXo0rzhhtitEhGRbJH4omzUqFGxm5Boyrdr+vUL62NeeGFYkum00+D008Ni5utStnaUrS3la0fZ2oqdb+KLsrq6uthNSDTl23XOwdSpoTgrKIDrrw8Tzq5YsfbzlK0dZWtL+dpRtrZi55v4oqy6ujp2ExJN+XbflCnw1FMweDA88kgYb7ZwYcvjXc121Sp44w34/e/hpJNgu+2gpCRs95xz4NFHoaoqzd9EjtJxa0v52lG2tmLn2yfq3kV6uV12CRcA7LsvvPlmuDLz8cdhq63af93KleFKzjffDIXYm2/C++9DY+Pnn/vii+Gj2cSJ4YrQHXcMnzfZBPIS/++ZiEj2S3xRNnTo0NhNSDTl23ObbBKmzDj4YHjllVAo/fnPsN12IdsVK+Dtt9cuwD744PPj0JyDTTeFL38Ztt02fIwbF4q3V14J86X9+98wY0b4+MMfwusGDw4FWvPH9tvDgAEZjSDjdNzaUr52lK2t2PkmfvLYuro6BiT9L0xEyjd96uvhO9+BP/4R8vNh//0/Y8aMPkyfHi4KaC0vDzbfPBRezUXYl74Egwa1v4/GxlDgvfJKS6H28cdrP6dPn7Ct1mfTRo5M3/eZDXTc2lK+dpStrUzk297ksYkvymbMmMHEiRMz2KLeRfmmV1MTnH9+WDezWZ8+sOWWLWe/vvzlsDJAOn5veA/z54firLlIe+edzxeBkyfDX/4SxqglgY5bW8rXjrL9vDvvhOuugwcfhLFje7atTOTbXlGW+O5LkVySlweXXQZ77AEvv7yYvfcezpZbQmGhzf6cg9Gjw8dRR4X7amtDN2frQu2FF2DXXeHpp2H4cJu2iIh0VXU1/L//BzU1oTC7/vrYLeqZxBdlAwcOjN2ERFO+NnbbDSZO/CxKt+GgQfD1r4cPCCsQ7LFHuJBg8mR45pncX7tTx60t5WtH2a7t8stDQQZwzz3wi19A377d317sfBPffem9xzmXwRb1LsrXTjZlu2QJ7Lln6NocOzYUZj3tJogpm7JNIuVrR9m2mDs3XE3e0BDGvX78MTzwABx2WPe3mYl8e/WC5DNnzozdhERTvnayKdthw+C558KVmXPmhLU7p0+P3aruy6Zsk0j52lG2LaZODQXZUUfBWWeF+5qvKu+u2PkmvigTkfQYPDhMdrvzzuE/0smT4b33YrdKRHqj995rWRXl0kvhmGPCRVF/+9vak3DnmsQXZXmaFdOU8rWTjdkWFcGTT4auzE8+CYP/2xk9kLWyMdskUb52lG1w7rnh6vGTToIvfCGczT/ggHDl+F13dX+7sfNN/JgyEUm/+no4/PCwdFNRETzxRJjPTCRp6urCFch77BGuVpb4XnwxnKkfNAhmz4aNNgr3P/ooHHhgmET7gw+y9/3q1WPK5s2bF7sJiaZ87WRztoWFYU6gww8PVz7ttVcY/J8rsjnbJEhSviefHI7vu++O3ZIgSdl2h/fw05+G22ed1VKQAeyzT5iy57//DaukdEfsfBNflNXX18duQqIpXzvZnm1BAdx7Lxx3XDibsN9+Yd3OXJDt2ea6pOS7aFE4xiEsfZYNkpJtdz38cFgveNgw+PGP136sTx+YMiXc7u6A/9j5Jr4oExE7+flw223wwx/CqlVwyCHhDJpIEtx8c1iaDMLEyStXxm1Pb/fZZ2EsGcAFF8AGG3z+Od/9bvh8//3hn8Vck/iibMyYMbGbkGjK106uZJuXB7/5DZx5ZvgDdvjh2dPVsz65km2uSkK+jY1w003h9oYbhoLs2WfjtgmSkW133XEHfPhhGNh/wgltP2fzzcPUPZ9+GpaG66rY+Sa+KKtpnupXTChfO7mUrXNhJu0LLghXP3372/D738du1frlUra5KAn5PvRQWM1i003h9NPDfY8+GrNFQRKy7Y6VK8O8ZBCmwGhv1v7vfS987k4XZux8E1+ULV26NHYTEk352sm1bJ2Diy6CK64Ig3FPPDF716HLtWxzTRLy/fWvw+dTTw1X9AE89lg4tmNKQrbdccMNYX7EbbaBI45o/7lHHhkuRnr2Waio6Np+Yueb+KJMRDLrpz+FX/0q3D799LA2XbrE/oMovcO778ILL4QxS9/+digESktDUfDWW7Fb1/ssXQr/93/h9hVXhCET7dlwQzj00HD7jjts25ZuiS/Khg0bFrsJiaZ87eRytv/v/8Ett4SzZ+edBz//eccFVV0dzJwJ//xnuOLtF7+AM84IY9S+9rWw1mb//rDLLmEtzp7I5WxzQa7n+5vfhM/HHRcKM+dg//3DfY89Fq9dkPvZdscVV8CyZbD77mHi6s5oHvB/++1hSEVnxc438ZPH1tbWMmjQoAy2qHdRvnaSkO2994YzDatXh26gr389jNP5+OPPf16+vPPb3XzzMC/aiBHda1cSss1muZzv0qVQVhb+SfjwwzCmDEIxdsABMGkSvP56vPblcrbdMX8+TJgQru5+/fWQf2c0NYV/5ObNC92Yu+3WuddlIt/2Jo/tY7rnLFBZWcnEiRNjNyOxlK+dJGR79NHh7NYRR4QxOs3jdNrSty+MHBm6iUaOXPt28+c+fcIZi//8J5wxe/bZcH9XJSHbbJbL+d5+eyjI9tijpSCDcJamf/+wrFhlZTgmY8jlbLvjwgtDQXb44Z0vyCB0cR53HFxySRjw39miLHa+iS/KRCSuQw4Jk8pedVUYfNtW0TVyJAwZ0rllUZ57LvzBfPfdlsJs9Gj770OSr6mppevy1FPXfqx//1CYPfZYOJ5/8IPMt6+3+eCDUCT36ROuuOyq73wnFGUPPBD+ISwqSncL0y/xRVlvOs0bg/K1k6Rs99yz82NBOjJsWCjE9toL3nyzpTAbO7bz20hSttkoV/P9+9/DWoqjR7eMIWvtgANCUfbYY/GKslzNtjvOPTcUyieeGLowu+oLXwi/H55/Hv70J/j+9zt+Tex8Ez/Qf/jw4bGbkGjK146yXb+SkjCm7CtfCZe877ILzJrV+dcrW1u5mm9z9/rJJ4fVKtbVXKg99VS82f1zNduueuWVsKTSgAFh/sPuah7w39k5y2Lnm/iibPbs2bGbkGjK146ybV9xMfzjH7DTTmEw8OTJYSHizlC2tnIx39mz4W9/g3794Pjj235OaSl8+ctxZ/fPxWy7qvWi4z/+cfcv6AH45jdh0KBQ5E2f3vHzY+eb+KJMRJKrqAiefDKcKVu4EHbdNVwEINJVN94YioGjjoKhQ9f/vAMOCJ+zYXb/pHr8cXjppXBG/Cc/6dm2Bg4MFwlAGJ+W7RJflOW3dQ5a0kb52lG2nTNoEDzxRBj8v3hxKMzeeaf91/QkW+/DWZJ99w3rfcrn5dqxW1cHt94abq87wH9drecrizGjVF5ebmXbVatXwznnhNvnn5+ewfnNXZh33hm2357Yx27ii7Jx48bFbkKiKV87yrbzBgwIZy722QeqqsLl72+8sf7ndzfbF18M295999DVde21nesS6W1y7di9994wOelXvxq6J9uz7bYts/u//XYmWtfiuutgm23G8fe/Z3a/mXTXXeFsd3k5nHRSera5007hQoHKyjDkoT2xj93EF2UVXV34SrpE+dpRtl1TWAh//WvoXlq6NBRO//pX28/taravvhquHp08OVzJNXgwbL11eOzuu3vW7iTKpWPX+7XXuexI69n9M9mFuWpVWLKsthaOPTYUGElTX98yqP+SS8L4vnRwLkyPAR0P+I997Ca+KGtoaIjdhERTvnaUbdf16xfmJDrssLBCwJ57wssvf/55nc122rTQTbnjjvD006Er5cILYc6ccNYCwn/2XVnGpTfIpWP35ZdDd/dGG4VB4Z0RY1zZAw+0LC9WVQVTpnTcFZdrfvObcNHO1luHiafT6dvfDhPKPvww/O9/639e7GM38UWZiPQuffvC/ffDkUfCp5/CN74R1tPsirffhoMOgu22C92UgwaFNTwrKmDq1LDg8S67wKhRMHduGJQsuan5LNkJJ3T+zMzXvx7OzDbP7p8JzZPannZaFRttFMY1XnllZvadCcuWhTOB0LlFx7uqrCz8k9bQELqrs1Xii7Ly8vLYTUg05WtH2XZfnz6hW3HKFFixIpztevrplsfXl+1//hPOlmyzDTzySBirdvbZ4czYpZeGbstmeXmhGwnCAGJpkSvHbmUlPPhgmJPsxBM7/7oBA8KFJRAuMrH21luhCz2cqS1ac7xdcEGY6iEJrroqnMHaZRfYe2+bfXRmzrLYx27ii7Jly5bFbkKiKV87yrZn8vPDL9/jjw/zSu2/fzjrBZ/Pdvr0MBXCVluFP9KFhXDGGfDRR+FsxPqmSJgyJXz+85/jTSaajXLl2P397+Gzz8JSYGVlXXttJrswf/vb8Pk734HGxmV84xtw1lmh+/Loo8NZplxWWdkyHODKKzu33Fp3HHRQmN/wzTfDMm1tiX3sqiiTHlG+dpRtz+Xnhz+8P/xhGCh98MHhDFhztrNmhUWLN988dHkWFITB3rNnhysrO5rce7PNwiLJNTVhu7ns4YfD0kHz5/d8W7lw7DY0wO9+F253ZoD/uvbbL3y2nt1/2TK4555w++STW7K97LLQvT53bnjfYkzPkS4XXRQyPOywsEqHlcLClrFq6ztbFvvYTXxRJiK9W15eGI/zox+FP8SHHQb3378h3/8+bLpp6HrMywvdV7NmwQ03hCkPOuvb3w6fc7ULc/78UKwefDDccksoUnP5D3xn/eUvsGgRbLlluKq2q0aODNNjWM/uf/vtYR+77w6bbNJyf9++cN99sMEG4SKAm2+2a4Ol6dPDHHH5+aHQtNbchXn33eH3QbbJaFHmnNvbOTfdOTfLOXdOG4/v6pxb7px7O/XRgxWvgtjrWCWd8rWjbNPHOfjlL8Ps4J99BlOnDl8zWej3vgczZ8JNN4WB+1115JFhDNvf/x4mr80Vn30Wuow22yycJdtggzBm7rnnWiZS7a5cOHZbT4PR3e6y5i7Mxx5LT5vW1dTU0nV5yinhc+tsx40Lxy2EfzpycTWL884L3bDHH7920Wnly18OhXhVVVg5YF2xj92MFWXOuXzgN8A+wObAUc65zdt46ove+y+lPi5Ow357uglph/K1o2zTy7kwXmXqVOjXzzNlSlgr89Zbw0SV3TVsWJi0dvXqcOYiF7zxRugmOuOMcCHEYYfBhx+2XOF31lk9u6ow24/dt94KU2FsuCEcc0z3t9O6KLM4u/jMM+EfhrKyln2tm+3RR4exZvX1cMQRuTW28bXXwhjO/v3Dz2UmONf+gP/Yx24mz5RtD8zy3n/kvW8A7gcOst7pokWLrHfRqylfO8o2/ZwL84y9/fZM7rwTxo9Pz3abuzDvuis927Py6adw+umw/fZhsPPo0WEs3AMPhO64I48MY6WWLw9nZrpbaGT7sdtcfH73u2G6k+5qnt1/wQKb2f2b23niieFsLLSd7Q03hLNM//lPWMA7F3gfin8I/xx0ZchATx17bMjziSdCF3ZrsY/dPhnc10ig9RDSBUBbQ/p2cM69A1QCZ3nvP3dC1jl3AnACQFlZGTNmzABg6NChFBYWsmDBAgAGDhyI937N43l5eYwfP5558+ZRX18PwJgxY6ipqWHp0qUADBs2jIKCAipT/yYOGjSI4cOHr1k5Pj8/n3HjxlFRUbFmkrny8nKWLVu2ZoDg8OHDcc6teXOLioooKSlhzpw5ABQUFDB27FjmzJlDY2MjAGPHjqW6upqamhoARowYgfeexan+kOLiYoqLi9fMNty3b1/Ky8uZPXs2q1MzCI4bN47FixdTW1sLQGlpKY2NjSxJzTg4ePBgioqKmDt3LgCFhYWMHj2aWbNm0ZSa/XLChAlUVlayYsUKmvOtr6+nqqoKgJKSEgYMGMD81Gjg5cuXA6zJGGDixInMnz+flal/2UaNGkVdXR3V1dXrfZ9KS0uZOXOm3qdW71Nz5ul4n/r378+oUaP0PqXep7q6WhoaGtL287TJJo6ionG8+WYeTzwxj/Hj67Pufbr55iWcf34xixcXkJ/vOfnklXz/+x8zcKBn6dKW9+knP+nD88+X89BDedxwQyV7713b5fepqqoq636emn/v1dcP4J57wqWW++wzhxkzGrv9Ps2cOYOdd96IP/6xmEcfhaFD0/fzVFnZh0cfHUtBAey220fMmLGaYcOG0dDQsOb4aP55qqyczZVX9uNb3xrNTTc5tt76E3bffVmH7xPE+703bdooXn65P0OGfMZhh1WwZMmGaf/7tL6fp1Wr5rPLLoN55plB/OEPjZxwQs2a96muro66ujrT33vt8t5n5AP4FnBLq6+nADes85wiYFDq9r7AzI62++Uvf9m3Z+HChe0+Lj2jfO0oWzsW2Z5wgvfg/dlnp33TPTJ3rvcHHhjaBt5vv733b73V/mt++9vw3OHDva+u7vo+s/nY/cUvwvf2jW+kZ3uPPBK2t9126dles3PPDds98si1728v21/9KrymuNj7ior0tiedGhq8nzgxtPXXv47ThoceCvvfbDPvm5pa7s/EsQtM8+upaTLZfbkAaD2MtoxwNmwN732N9742dfsJoMA5t54ZgjqnpKSkJy+XDihfO8rWjkW2zV2Y99yTHcvffPZZuLhh881DF+UGG4TB7a+8Al/6UvuvPfFE2HnncOFCcxdTV2Trsbt6dcvA+e5Mg9GW3XcPUy28/josXJieba5aFa6EhZYB/s3ay/bUU+HAA8M0GkcfHY6BbHTzzTBjRlgk/IQT4rRh333D0loffgj//nfL/bGP3UwWZa8DE5xzY51zfYEjgbVm9nHOjXCpUXbOue1T7avuyU6bT8mKDeVrR9nasch2xx3hC1+Ajz8OVzDGNG1aGDf24x+Hgfzf/Ga4qOGUU8LUAx3Jywt/OPv1C4OhW6+G0BnZeuz+7W9hdYaxY8PFGenQenb/tq7m644HH4RPPglrQO6009qPtZetc3DbbWF84CuvhPGT2aampqVdV1wR5gaMoaCgZUWO1gP+Yx+7GSvKvPefAacCfwc+BP7kvf+Pc+4k59xJqad9E3g/NabsV8CRqVN9IiJZzbmWGf5jDfivqQlTI3zlK+EKw9Gjw4zzf/5z1wdSb7JJWMYHwuSkqWE8Oa15GoyTT+5ccdpZ6Z7dv3mA/8knd326jpKScLY2Ly+sJWk5h1p3XHVVWFh9p53CSgoxNV+Fef/9WXTV6vr6NXPlo6MxZR999FHnO3qly5SvHWVrxyrbmTPDOJWBA72vrTXZRZuamrz/y1+8Hzky7D8/3/uzzup5GxoavP/iF8M2zzij86/LxmN3+vTwfRQWdm+cXHsWLAjbHjDA+7q6nm3rrbfCtoqKvP/0088/3tlsL7ggbGfjjb3/5JOetSldFizwvn//0K5XXondmmDSpNCee+4JX2fi2CVLxpRFMXbs2NhNSDTla0fZ2rHKdvz40I25YgX89a8mu/ic1avDVBaHHhq6TrffPnRf/uIXMHBgz7ZdUBDmccvLg+uvX3vsTXuy8dhtHkt2zDEwZEh6t908u39dXc+7rluvc9nWdB2dzfb888O4wIULwxmhbOhzuuCCluWUdtghdmuCdecsi33sJr4oi90/nHTK146ytWOZbaaXXbr1VvjTn8JA/t/8pnMD+bviy1+GM88Ms8sff3znlqbJtmO3trblj+66A+fTJR1dmK3XufzhD9t+Tmez7dMnbGvw4DDW7frru9+udHjvvfAe9OkD//d/cdvS2lFHhbGTzzwD8+bFP3YTX5Q1z7MiNpSvHWVrxzLbww8P6xI+/XQ4c2Xpf/+Dc88Nt2+5Jf1jpZpdeGFY0uf998OqCB3JtmP37rvDeLuddoJttrHZRzpm97/jjnC2bffdw7qsbelKtqNGhYH/AGefHSYMjuXss0MuP/xhuOoyWwweHNZ99T7kH/vYTXxRJiKSSYMHhz/Q3sO999rua+pUqK6GXXeFb33Lbj8DBrQseH3JJfDBB3b7Sjfv117n0so228DGG4fZ/d95p+uvb73O5cknp69dBx8cttfYGLq5P/00fdvurKefhiefhKKilotHsklzF+btt4f3IabEF2Wx+4eTTvnaUbZ2rLNtvgrzzjvtxvK8+274I56XB7/6VfcX1e6s3XYLV2E2NsL3v9/+XGzZdOw+/3xYfmjEiDDuzkpeHuy/f7jdnS7MZ58Nc3eVlYW5xtanO9lefTVstVVYR9Oq+3Z9mprCWTKAn/0MhvZo5lEbe+wRcv/oI/j44y9EbUvii7LmpRPEhvK1o2ztWGe7zz5haoL33+/eWZOOeA+nnRb+4J18cviDmwlXXRXOBr36astZnbb0NN958+B3v4OHHw5n5Vat6v62ms+SnXhi6Fa21JNxZW2tc9mW7mTbvz/88Y/h8113ZXbKlnvuCdOzlJWF6VqyUX5+y1jQ3/9e3ZemmtfqEhvK146ytWOdbd++YQAx2Az4/9OfwhmgkhK4+OL0b399iotbirGf/QxSyxR+TnfzbWwMZ3U22wxOOil0vW2xRSgmxo6FvfYKXZDXXx8Wk541q/1Z6+fPh4ceCkVOJmaO7+7s/vPnh1UXCgrCWcj2dDfbzTYLZ1QhjOtKLeVoauVKOO+8cPvSS8P7mK2+853w+ckn+3bqYhYriS/KRERiaO7CvPfe9C53s2JFy9JHl18exrBl0sEHhxUCVqwIhVO6umdfew0mTYKf/CQMdv/GN2DvvcMFBnl5UFEBTz0Vziidfjrst18YMN6/P0ycGLoOzzgjFI1PPx0KxhtvDN2shx3W9clzu2PAgFCYQSgaO+t3vwtnPQ87LHSzWjn++HAhyooV4X1MrUlu5oYbQsH5xS+2zJ6frSZMCD+rf/97hfkZ1XatbwKzXPnoaPLY5cuXd3liN+k85WtH2drJRLZNTd5vskmYmPKJJ9K33fPOC9vcdlvvP/ssfdvtioULvR88OLTjzjs//3hX8v3f/7w/6STvnQvbGzv283mtWuX9f//r/aOPen/tteH5u+/u/ejRfs1C6+19vPhiD7/hLrjpprDPgw7q3PPr673faKPwmhde6Pj5PT12ly0Li3CD9+PH2y1cXlXl/YYbhv384x82+7CQid8NtDN5bDs918ngs2HGvARTvnaUrZ1MZNu87NLPfx66MNOx1uLs2WFSWAhnISymv+iMESPg2mvDVWunnx7Oam20UcvjncnXe7jvvnB265NPQhfjT34S8howYO3n9u0bln3aZJPPb2flypDLjBmhS27mzJbbixbBLrt8fv1IS82D/Z96CurrQ3dme/7yl/D9b7UVfO1rHW+/p8fuhhuGru+99oK33w4TzD7zTPqnqbjkEli+POxnzz3Tu21L0X/vrq9ay5WPjs6UTZ8+vfPlq3SZ8rWjbO1kKtuKCr9maZ90/AN+4IFhe1Om9HxbPdXU5P2ee4b2HHnk2o91lO/MmS2vBe+/9jXv338//W2srfV+9er0b7cj224bvq/HH+/4uTvtFJ57002d23a6jt2lS73fccew7+HDvX/nnbRs1nvv/axZ3hcUhLOf6dxuJmTidwO9eZklEZFYxowJc4jV18MDD/RsW08+GQaDDxrUuQlcrTkXxkINGBAWdH7ssY5fs2pVOIOy5ZbhTNKQIWFFguefDwP6023gwDAeLdNaTyTbnnfegZdfDvN3HXOMfbtaKy6Gf/wjjIFbvDgcp51dRqsj554bLto47jjYeuv0bLO3SHxRVlxcHLsJiaZ87ShbO5nMtnnAf0+mIWhoaJlO4IILwrQU2WDs2HBVHYRB/80XBraV7z//GQZ8X3BBKM6OOw7++1/43vfiFE6WmrswO5rdv/lK1uOOa3udy7ak89gdODC08cADYenSUKA9/3zPtvmvf4Wrg/v3DwV4ron9ezdhPwqfFzvgpFO+dpStnUxm+81vhnFF//zn+qeQ6MivfhXGSU2cmH1zPZ12WlgE/eOP4ac/Dfe1znfJklB07LYbTJ8exoU991yYPX3YsChNNrfttqFwnj9//fPULVsWln+C9a9z2ZZ0H7uFheEs7tFHhzVC9967a1eOtuZ9y5XBZ5wR5ibLNbF/7ya+KKuoqIjdhERTvnaUrZ1MZltUFKYfgJbFprti4UK46KJw+/rr7SdA7ar8/NAFWVAAN90EL7wQ8m1qCvdvumm40KFfv3Dm5J13QldZknVmdv877wxTf3z962EOsc6yOHYLCkJ7TjghdLUffDD8+c9d387DD8NLL4VZ+5tn8c81sX/vJr4oExGJrXm28O4su3TOOeEMxgEHhLMY2WjLLcNkshCWYnr//X7sskuYCPV//wtX373/friysl+/uG3NlPZm9/e+pesy08serU9+fiiqzzyzZZ3M22/v/OsbG1vOlE6dGq7ylK5LfFHWN9v+rUwY5WtH2drJdLZ77gnDh4fuu9df7/zrXnklFHJ9+8Ivf2nXvnQ499xwxmfGDDjssDG89FL4nsOEnDB+fOwWZlbr2f3XnaT12WfDsTByZPvrXLbF8th1Lky5cuGFYTLb7343TL3SGbfcEt77CRPCUlG5Kvbv3cQXZeXl5bGbkGjK146ytZPpbPv0CWN2oPMD/levDuO1IIzTGTfOpm3p0q9f6K50Lnz88IdhIP9RR9kvlp6NWs/u//jjaz/W2XUu22J97DoXznRdc034+rTTwsoR7fn001DIAVxxRegOzVWxf+8mviibPXt27CYkmvK1o2ztxMi2uQvzvvvo1Np6t90Gb7wRzqace65t29Jlhx3C1XePPTaf3/42TLvQm7XVhTl/fhh71adP6Ortqkwduz/+Mfz+96FIO++80D29vq73q64KE+DuuCMcckhGmmcm9u/dxBdlq1evjt2ERFO+dpStnRjZfvGLYexVdXWYc6w9S5e2FGJXXx2mLsgV220H48evjN2MrLDu7P4QCp2erHOZyWP3Bz8IF6fk54czYKeeGtreWmVly1m1X/wi98+Kxv69m/iiTEQkGzi39oD/9kydClVVMHkyHHGEfdvExsiRsM024SrL554LZ0hvvjk8li0D/Dty1FFhKah+/cLFCd/9Lnz2WcvjF1wQlro67LBwpkx6xvnY6zz10KRJk/y0adPW+/jq1avJj7VAXC+gfO0oWzuxsq2shFGjQtfVokUwePDnn/Pee+EPuffw5pvhDFuu0bHbYupUuPjiMMZu8uRQ5Gy5Jbz7bvfOKsXK9plnwkUJdXVw6KHhAo6ZM8PxmZcHH3yQ/vUzY8hEvs65N7z3k9p6LPFnyhYvXhy7CYmmfO0oWzuxsi0tDYO/GxrCrOfr8j4MrF69OvwRz8WCDHTsttZ6XFnzAP9TTul+N1+sbHffPXTDbrhhOHN20EFh3FlTUzhWk1CQQfxjN/FFWW1tbewmJJrytaNs7cTMtr0uzAceCDP/l5SEsyu5Ssdui+bZ/RcsCBOrbrABHHts97cXM9sddwzdsEOHhmlOnnoqTI58/vnRmpR2sY/dxBdlIiLZ5JBDwsD9V16B1hd6rVgRJu4EuOyysFi35L68PNhvv5avu7LOZTbaZht48cUwXg7C5MZJXS4rhsQXZaWlpbGbkGjK146ytRMz24EDw6BoWHvOsiuvDNMlbLNNmAk/l+nYXVtzFybAySf3bFvZkO2mm8K0aaEbs3kW/6SInW/ii7LGxsbYTUg05WtH2dqJne2UKeHzXXeFcWQffRTmeoIwg3quj5GPnW+22XPPMMj/xBO7ts5lW7Il2xEjwlnfvIRVEbHzTVicn7dkyZLYTUg05WtH2dqJne1uu4Xun48+Ct2YZ54Jq1bBMcfATjtFbVpaxM432/TvD88/H9aW7Cllayt2vokvykREsk1+fstg71NPhYceCt2azWfLRKR3SnxRNritiYAkbZSvHWVrJxuybe7CfPvt8Pn888OUGUmQDfkmlbK1FTvfxBdlRUVFsZuQaMrXjrK1kw3ZbrFFmC4BwhxPp58etTlplQ35JpWytRU738QXZXPnzo3dhERTvnaUrZ1syfa882D06LAeYr9+sVuTPtmSbxIpW1ux8+0Tde8iIr3YoYeGDxER6AVnygoLC2M3IdGUrx1la0fZ2lK+dpStrdj5Jn5BchEREZFs0asXJJ81a1bsJiSa8rWjbO0oW1vK146ytRU738QXZU1NTbGbkGjK146ytaNsbSlfO8rWVux8E1+UiYiIiOSCxI8p897jnMtgi3oX5WtH2dpRtraUrx1laysT+fbqMWWVlZWxm5BoyteOsrWjbG0pXzvK1lbsfBNflK1YsSJ2ExJN+dpRtnaUrS3la0fZ2oqdb+KLMhEREZFckPiirKysLHYTEk352lG2dpStLeVrR9naip1v4ouy+vr62E1INOVrR9naUba2lK8dZWsrdr6JL8qqqqpiNyHRlK8dZWtH2dpSvnaUra3Y+Sa+KBMRERHJBTk/T5lzbgkwt52nDAX0r4Ud5WtH2dpRtraUrx1laysT+Y7x3g9r64GcL8o64pybtr5J2qTnlK8dZWtH2dpSvnaUra3Y+ar7UkRERCQLqCgTERERyQK9oSj7fewGJJzytaNs7ShbW8rXjrK1FTXfxI8pExEREckFveFMmYiIiEjWS3RR5pzb2zk33Tk3yzl3Tuz2JIlzrsI5955z7m3n3LTY7cl1zrnbnHOfOOfeb3XfEOfcU865manPg2O2MVetJ9sLnXMfp47ft51z+8ZsY65yzo1yzj3nnPvQOfcf59yPUvfr2E2DdvLV8dtDzrlC59y/nXPvpLK9KHV/1GM3sd2Xzrl8YAawJ7AAeB04ynv/QdSGJYRzrgKY5L3XfDlp4JybDNQCd3rvt0zddxXwP+/9Fal/KgZ7738as525aD3ZXgjUeu+vjtm2XOec2xjY2Hv/pnNuA+AN4GDgO+jY7bF28j0cHb894pxzwEDvfa1zrgB4CfgRcCgRj90knynbHpjlvf/Ie98A3A8cFLlNIm3y3r8A/G+duw8C7kjdvoPwy1i6aD3ZShp47xd6799M3f4U+BAYiY7dtGgnX+khH9SmvixIfXgiH7tJLspGAvNbfb0AHczp5IF/OOfecM6dELsxCTXce78Qwi9nYKPI7UmaU51z76a6N9W91kPOuXJgG+Bf6NhNu3XyBR2/Peacy3fOvQ18AjzlvY9+7Ca5KHNt3JfMvto4dvLebwvsA5yS6iISyRU3AuOALwELgWuitibHOecGAQ8Cp3vva2K3J2nayFfHbxp471d7778ElAHbO+e2jNykRBdlC4BRrb4uAyojtSVxvPeVqc+fAH8ldBdLei1OjSlpHlvySeT2JIb3fnHqF3ITcDM6frstNR7nQeAe7/1fUnfr2E2TtvLV8Zte3vtlwD+BvYl87Ca5KHsdmOCcG+uc6wscCTwSuU2J4JwbmBp0inNuILAX8H77r5JueAQ4LnX7OODhiG1JlOZfuimHoOO3W1KDpW8FPvTeX9vqIR27abC+fHX89pxzbphzrjh1uz+wB/BfIh+7ib36EiB1mfB1QD5wm/f+srgtSgbn3BcIZ8cA+gD3Ktuecc7dB+wKDAUWA1OBh4A/AaOBecC3vPcasN5F68l2V0LXjwcqgBObx5FI5znnvga8CLwHNKXuPpcw7knHbg+1k+9R6PjtEefc1oSB/PmEE1R/8t5f7JwrIeKxm+iiTERERCRXJLn7UkRERCRnqCgTERERyQIqykRERESygIoyERERkSygokxEREQkC6goExEREckCKspEJNFSk0T+1jlX4Zxb5Zxb7Jx7xjm3Z+rxCufcWbHbKSLSJ3YDRESMPQgMAI4HZhEWGN4FKInZKBGRdWnyWBFJrNQyKkuBPb33T7fx+D8JBdoa3nuXemxH4P+A7VLbeAT4afOC26nX/hdYBXw79fJbUs9pQkSki9R9KSJJVpv6ONA5V9jG44cCC4CLgY1THzjntgL+QSjEvph63peA29Z5/TGE36M7ACcCJwCnp/l7EJFeQmfKRCTRnHOHATcTujDfAl4G/uy9/1fq8Qrg1977q1u95k6g0Xt/fKv7vpR6/XDv/SepM2WlwCY+9YvUOfdz4CTvfVkGvjURSRidKRORRPPeP0gong4A/gbsCLzmnDu3nZd9GTjWOVfb/EEo5gDGtXrea37t/2xfBUY654rS9x2ISG+hgf4iknje+3rgqdTHxc65W4ALnXNXr+cleYTxYb9s47GPbVopIr2dijIR6Y0+IPz+KwQagPx1Hn8T2MJ7P6uD7XzFOedanS37KlDZfDGAiEhXqPtSRBLLOVfinHvWOXesc25r59xY59y3gLOBZ1LFUwWws3NupHNuaOqlVwLbO+ducs5t45wb75zb3zn3u3V2UQpc55zbxDn3TeAntH12TUSkQzpTJiJJVgu8BvwIGA/0I3Q/3gtcmnrOBcDvgNmpx533/l3n3OTUc54nnEn7CPjrOtu/J/XYvwAP3IqKMhHpJl19KSLSDamrL9/33p8auy0ikgzqvhQRERHJAirKRERERLKAui9FREREsoDOlImIiIhkARVlIiIiIllARZmIiIhIFlBRJiIiIpIFVJSJiIiIZAEVZSIiIiJZ4P8DKzOXr+WMWe0AAAAASUVORK5CYII=\n"
            ]
          },
          "metadata": {
            "image/png": {}
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "metadata": {
        "datalore": {
          "node_id": "Giwx5P1RjMXmeZmQh03MmW",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {
            "rowId": "lqcBfd1WNHNs3dGpFcZXNZ"
          }
        },
        "id": "jgHTaYQc6kMb",
        "outputId": "9a3e793b-9aa2-4e3c-be4e-6929f558d7da"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "LU6Xk05rez5UKKGOq6xsc1",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "UadxYJD66kMb"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python"
    },
    "datalore": {
      "computation_mode": "JUPYTER",
      "package_manager": "pip",
      "base_environment": "default",
      "packages": [],
      "report_row_ids": [],
      "report_tabs": [
        {
          "id": "1GjCvsYSqrUL1GG4rSALjd",
          "name": "Report tab",
          "rows": [
            "3ZG9LkMBswg7vdNgrxr35R",
            "sqofyOVXSsqTYKwVTBMqf2",
            "xhQJES9q8LzFEdDFZUknqq",
            "4MoNjS7bxWO7vMCWnjX11b",
            "pBEqrMuk5fbJlQpfumfJ5g",
            "sCmXNGg3E01Oq1fGnfp8zn",
            "Gksby1b0CqwwLnxUVgxq6z",
            "mzaoFLw5IL170UzgwlvWWS",
            "UeVWy67Obm8FqvkZQsR1FG",
            "Uibx73yiDjm2zd82k857Yn",
            "HKhbcfi7JLQS5U4WnyNXSc",
            "XymLign4hYiAdiQthezGWR",
            "W8vzrsa8Lok7QByxI67Xq9",
            "9VI9rr0panAFfG33wng4KX",
            "eFJNtoJzoLNzTvJ4HiU09x",
            "59eYJaQJw2qp8cxe2Zn1Sb",
            "DPidKdHCMYHhzQxTDEFDji",
            "RImQsFRrhelOahiW4htyR0",
            "JGLViHEfrvAIM9p7DTvqz9",
            "d8ruNav4nOSqbzt1xxuznU",
            "9IeydbuBlR2D7DrHh5Jxj6",
            "Ma2TmHFOoGU3kK3g3XpgTn",
            "4dhNMEeO6DsbPeaGtKgGLT",
            "lqcBfd1WNHNs3dGpFcZXNZ",
            "Xx8SQPu0nOz2ISdWAHLnqW",
            "1dwb5yRPWHIZMHQoiT9emB",
            "BBZ9TWCxYJ9egax4oktUcH"
          ]
        }
      ],
      "version": 4
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}