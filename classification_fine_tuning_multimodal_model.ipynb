{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary package for unsupervised learning\n",
        "! pip install unsloth"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "NU7Sny65qtT02ATDL1L5Ui",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "KBpTuEb06ZnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Define the path for the training dataset (ensure no sensitive info in path). The dataset should contain two columns:\n",
        "# - \"mail\": This is the input text to be used for training.\n",
        "# - \"Catégorie du ticket\": This is the annotation, representing the target category for classification.\n",
        "HOME_PATH = '/home/ubuntu'\n",
        "train_dataset_name = os.path.join(HOME_PATH, \"train_set_filtred.csv\")\n",
        "\n",
        "\n",
        "# Load the dataset from CSV file\n",
        "dataset = load_dataset(\"csv\", data_files = train_dataset_name)\n",
        "\n",
        "# Print dataset details: number of prompts and column names\n",
        "print(f'Number of prompts: {len(dataset)}')\n",
        "print(f'Column names are: {dataset.column_names}')"
      ],
      "metadata": {
        "id": "oMPNDBRAcofE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary components from unsloth for vision model\n",
        "from unsloth import FastVisionModel\n",
        "import torch\n",
        "\n",
        "# Load pre-trained vision model with options for memory optimization (4-bit)\n",
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "    \"unsloth/Llama-3.2-11B-Vision-Instruct\",\n",
        "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "5qoeYZU4NXxVSDTZyKUiSd",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "CiezChC26ZnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply PEFT (Progressive Fine-Tuning) to vision and language layers\n",
        "model = FastVisionModel.get_peft_model(\n",
        "    model,\n",
        "    finetune_vision_layers     = False, # False if not finetuning vision layers\n",
        "    finetune_language_layers   = True, # False if not finetuning language layers\n",
        "    finetune_attention_modules = True, # False if not finetuning attention layers\n",
        "    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n",
        "\n",
        "    r = 16,           # The larger, the higher the accuracy, but might overfit\n",
        "    lora_alpha = 16,  # Recommended alpha == r at least\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "Gk3gJLgmNgqz6qh9okm5bZ",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "UDBsJjwJ6ZnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt for ticket classification assistant\n",
        "prompt = \"\"\"\n",
        "Tu es un assistant spécialisé dans la classification de tickets à partir de leur contenu textuel. Ton objectif est d’analyser la description fournie et de l’associer à l’une des catégories ci-dessous :\n",
        "```\n",
        "Demande de service/Backup #BCS/Autre\n",
        "Demande de service/Backup #BCS/Demande de renseignement\n",
        "Demande de service/Backup #BCS/Restauration qualifiée\n",
        "Demande de service/Backup #BCS/Stratégie de sauvegarde/Création\n",
        "Demande de service/Backup #BCS/Stratégie de sauvegarde/Modification\n",
        "Demande de service/Backup #BCS/Stratégie de sauvegarde/Suppression\n",
        "Demande de service/Cyber Sécurité #CS2/Bastion/Création-Modification d'entrées\n",
        "Incidents/Backup #BCS/Sauvegarde\n",
        "Incidents/Supervision\n",
        "```\n",
        "### Règles :\n",
        "1. Réponds uniquement par la catégorie exacte, sans texte supplémentaire.\n",
        "2. La catégorie associée doit être unique.\n",
        "3. Si aucune catégorie ne correspond, la valeur de \"categorisation\" doit être \"unknown\".\n",
        "\n",
        "### Exemple :\n",
        "La description:\n",
        "Bonjour¤ Merci de relancer les sauvegardes FULL¤ si ils ne sont pas repassées en automatique. Thomas Envoyé de mon iPhone Début du message transféré\n",
        "#### Sortie :\n",
        "{{\n",
        "  \"categorisation\": \"Incidents/Backup #BCS/Sauvegarde\"\n",
        "}}\n",
        "\n",
        "Analyse uniquement la description suivante :\n",
        "{content}\n",
        "\"\"\"\n",
        "\n",
        "# Format for predicting the category for each sample\n",
        "prediction_format = \"\"\"\n",
        "{{\n",
        "  \"categorisation\": \"{category}\"\n",
        "}}\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "KrkRiHUFgPjFET8DVhl87a",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "i8mkj4Ns6ZnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to convert data into a conversation format\n",
        "def convert_to_conversation(sample):\n",
        "    new_conversation = [\n",
        "        { \"role\": \"user\",\n",
        "          \"content\" : [\n",
        "              {\n",
        "                  \"type\" : \"text\",\n",
        "                  \"text\" : prompt.format(content = sample[\"mail\"])\n",
        "              }\n",
        "          ]\n",
        "        },\n",
        "        { \"role\": \"assistant\",\n",
        "          \"content\" : [\n",
        "              {\n",
        "                  \"type\" : \"text\",\n",
        "                  \"text\" : prediction_format.format(category = sample[\"Catégorie du ticket\"])\n",
        "              }\n",
        "          ]\n",
        "        }\n",
        "    ]\n",
        "    return {\"messages\" : new_conversation}"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "wRrra0U3tnLIAOaSMtp73N",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "j8FeKZ0g6ZnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to a conversation format\n",
        "converted_dataset = [convert_to_conversation(sample) for sample in dataset['train']]\n",
        "print(converted_dataset[0])"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "tSCOZkpoh9o7nAoPvPbEcv",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "59Sl_hdv6ZnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to format prompts for tokenization\n",
        "def formatting_prompts_func(examples):\n",
        "    try:\n",
        "        convos = examples[\"dataset\"]\n",
        "        texts = [tokenizer.apply_chat_template(convo['messages'], tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "        return { \"text\" : texts, }\n",
        "    except:\n",
        "        print(examples)\n",
        "        raise"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "Ns6V7ZwmP0y8ea5bdr13IA",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "CeBP_ehW6ZnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to a format suitable for processing\n",
        "from datasets import Dataset\n",
        "my_dataset = Dataset.from_dict({\"dataset\": converted_dataset})"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "YUtAso2FIDawYbaXWKYOW7",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "3KkYaY0C6ZnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply formatting to the dataset\n",
        "dataset = my_dataset.map(formatting_prompts_func, batched = True,)\n",
        "dataset[2]['text']"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "XPVg5LmEmjYXGjEc6ivZBb",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "YgxuawqR6ZnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess function for batch tokenization\n",
        "from functools import partial\n",
        "def preprocess_batch(batch, tokenizer, max_length):\n",
        "    \"\"\"\n",
        "    Tokenizes dataset batch\n",
        "\n",
        "    :param batch: Dataset batch\n",
        "    :param tokenizer: Model tokenizer\n",
        "    :param max_length: Maximum number of tokens to emit from the tokenizer\n",
        "    \"\"\"\n",
        "\n",
        "    return tokenizer(\n",
        "        images=None,\n",
        "        text=batch[\"text\"],\n",
        "        max_length = max_length,\n",
        "        truncation = True,\n",
        "    )\n",
        "\n",
        "\n",
        "def preprocess_dataset(tokenizer, max_length: int, seed, my_dataset: str):\n",
        "    \"\"\"\n",
        "    Tokenizes dataset for fine-tuning\n",
        "\n",
        "    :param tokenizer (AutoTokenizer): Model tokenizer\n",
        "    :param max_length (int): Maximum number of tokens to emit from the tokenizer\n",
        "    :param seed: Random seed for reproducibility\n",
        "    :param dataset (str): Instruction dataset\n",
        "    \"\"\"\n",
        "    columns_names = my_dataset.column_names\n",
        "    columns_names.append('text')\n",
        "\n",
        "    # Apply preprocessing to each batch of the dataset & and remove initial columns and \"text\" fields\n",
        "    _preprocessing_function = partial(preprocess_batch, max_length = max_length, tokenizer = tokenizer)\n",
        "    my_dataset = my_dataset.map(\n",
        "        _preprocessing_function,\n",
        "        batched = True,\n",
        "        remove_columns = columns_names,\n",
        "    )\n",
        "    # Filter out samples that have \"input_ids\" exceeding \"max_length\"\n",
        "    my_dataset = my_dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
        "    # Shuffle dataset\n",
        "    my_dataset = my_dataset.shuffle(seed = seed)\n",
        "\n",
        "    return my_dataset"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "BbMKJ0Vq3GtA5j9XOn3UKp",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "KQq3f_0h6ZnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the dataset with a max length of 2048 tokens\n",
        "max_length = 2048\n",
        "seed = 33\n",
        "preprocessed_dataset = preprocess_dataset(tokenizer, max_length, seed, dataset)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "AUNmTbe1iLKsGqffAYDrPt",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "B7INHhL_6ZnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print dataset\n",
        "preprocessed_dataset"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "zj6RhOfEb54RZbOZ9VTtIe",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "HZrcrG5O6ZnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define data collator for batching input during training\n",
        "class TextDataCollator:\n",
        "    def __init__(self, model, tokenizer, max_length=2048):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __call__(self, examples):\n",
        "        # Pad or truncate input_ids and attention_mask\n",
        "        input_ids = [ex[\"input_ids\"][:self.max_length] for ex in examples]\n",
        "        attention_mask = [ex[\"attention_mask\"][:self.max_length] for ex in examples]\n",
        "\n",
        "        # Pad sequences to max_length\n",
        "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "            [torch.tensor(ids) for ids in input_ids],\n",
        "            batch_first=True,\n",
        "            padding_value=0\n",
        "        )\n",
        "\n",
        "        attention_mask = torch.nn.utils.rnn.pad_sequence(\n",
        "            [torch.tensor(mask) for mask in attention_mask],\n",
        "            batch_first=True,\n",
        "            padding_value=0\n",
        "        )\n",
        "\n",
        "        # Add labels (same as input_ids for language modeling)\n",
        "        labels = input_ids.clone()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "yideAsRlmjsmp5VvH4V5sE",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "3w5m7bQX6ZnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import is_bf16_supported\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "# Set up the training configuration and trainer\n",
        "\n",
        "FastVisionModel.for_training(model) # Enable for training!\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator =  TextDataCollator(model, tokenizer),\n",
        "    train_dataset = preprocessed_dataset,\n",
        "\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        #max_steps = 30,\n",
        "        num_train_epochs = 1, # Set this instead of max_steps for full training runs\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bf16_supported(),\n",
        "        bf16 = is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\",     # For Weights and Biases\n",
        "\n",
        "        # You MUST put the below items for vision finetuning:\n",
        "        remove_unused_columns = False,\n",
        "        dataset_text_field = \"\",\n",
        "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
        "        dataset_num_proc = 4,\n",
        "        max_seq_length = 2048,\n",
        "    ),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "lcCkIhvDx20oIROvskJMZW",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "eypR7wZ36ZnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training and track stats\n",
        "trainer_stats = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "ofUEdZ07emKfi5n8NzojZu",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "ia2Llgbc6ZnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Save training logs to a CSV file\n",
        "pd.DataFrame(trainer.state.log_history).to_csv(os.path.join(HOME_PATH,\"llama_ft_log.csv\"))"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "anFmjLF9Mr7UEzbqPDjZee",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "mosEIW-36ZnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display training logs in DataFrame\n",
        "df = pd.DataFrame(trainer.state.log_history)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "6gDml1GzyjgMAzeTjWMC5Z",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "vzpxTrhE6ZnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the training loss curve\n",
        "loss = df['loss']\n",
        "step = df['step']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(step, loss, label='Loss', color='blue', linewidth=2)\n",
        "\n",
        "plt.title(\"Loss Curve\", fontsize=16)\n",
        "plt.xlabel(\"Step\", fontsize=14)\n",
        "plt.ylabel(\"Loss\", fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.legend(fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "q5zSZ9hWB8IJtG0Fp9uYsk",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "kqWPAKGe6ZnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Push trained model and tokenizer to Hugging Face Hub (ensure tokens are replaced by placeholders)\n",
        "model.push_to_hub(\"your_hf_hub\", token=\"hf_XXXXXXXX\")\n",
        "tokenizer.push_to_hub(\"you_hf_hub\", token=\"hf_XXXXXXXXXX\")"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "XWONoiNrcQ6QIFKwqz8vfQ",
          "type": "CODE",
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true
        },
        "id": "lUtqwDfx6ZnE"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python"
    },
    "datalore": {
      "computation_mode": "JUPYTER",
      "package_manager": "pip",
      "base_environment": "default",
      "packages": [],
      "report_row_ids": [],
      "report_tabs": [],
      "version": 4
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}